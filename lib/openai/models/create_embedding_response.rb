# frozen_string_literal: true

module OpenAI
  module Models
    class CreateEmbeddingResponse < OpenAI::BaseModel
      # @!attribute data
      #   The list of embeddings generated by the model.
      #
      #   @return [Array<OpenAI::Models::Embedding>]
      required :data, -> { OpenAI::ArrayOf[OpenAI::Models::Embedding] }

      # @!attribute model
      #   The name of the model used to generate the embedding.
      #
      #   @return [String]
      required :model, String

      # @!attribute object
      #   The object type, which is always "list".
      #
      #   @return [Symbol, :list]
      required :object, const: :list

      # @!attribute usage
      #   The usage information for the request.
      #
      #   @return [OpenAI::Models::CreateEmbeddingResponse::Usage]
      required :usage, -> { OpenAI::Models::CreateEmbeddingResponse::Usage }

      # @!parse
      #   # @param data [Array<OpenAI::Models::Embedding>]
      #   # @param model [String]
      #   # @param usage [OpenAI::Models::CreateEmbeddingResponse::Usage]
      #   # @param object [Symbol, :list]
      #   #
      #   def initialize(data:, model:, usage:, object: :list, **) = super

      # def initialize: (Hash | OpenAI::BaseModel) -> void

      # @see OpenAI::Models::CreateEmbeddingResponse#usage
      class Usage < OpenAI::BaseModel
        # @!attribute prompt_tokens
        #   The number of tokens used by the prompt.
        #
        #   @return [Integer]
        required :prompt_tokens, Integer

        # @!attribute total_tokens
        #   The total number of tokens used by the request.
        #
        #   @return [Integer]
        required :total_tokens, Integer

        # @!parse
        #   # The usage information for the request.
        #   #
        #   # @param prompt_tokens [Integer]
        #   # @param total_tokens [Integer]
        #   #
        #   def initialize(prompt_tokens:, total_tokens:, **) = super

        # def initialize: (Hash | OpenAI::BaseModel) -> void
      end
    end
  end
end
