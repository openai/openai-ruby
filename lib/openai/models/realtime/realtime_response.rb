# frozen_string_literal: true

module OpenAI
  module Models
    module Realtime
      class RealtimeResponse < OpenAI::Internal::Type::BaseModel
        # @!attribute id
        #   The unique ID of the response.
        #
        #   @return [String, nil]
        optional :id, String

        # @!attribute conversation_id
        #   Which conversation the response is added to, determined by the `conversation`
        #   field in the `response.create` event. If `auto`, the response will be added to
        #   the default conversation and the value of `conversation_id` will be an id like
        #   `conv_1234`. If `none`, the response will not be added to any conversation and
        #   the value of `conversation_id` will be `null`. If responses are being triggered
        #   by server VAD, the response will be added to the default conversation, thus the
        #   `conversation_id` will be an id like `conv_1234`.
        #
        #   @return [String, nil]
        optional :conversation_id, String

        # @!attribute max_output_tokens
        #   Maximum number of output tokens for a single assistant response, inclusive of
        #   tool calls, that was used in this response.
        #
        #   @return [Integer, Symbol, :inf, nil]
        optional :max_output_tokens, union: -> { OpenAI::Realtime::RealtimeResponse::MaxOutputTokens }

        # @!attribute metadata
        #   Set of 16 key-value pairs that can be attached to an object. This can be useful
        #   for storing additional information about the object in a structured format, and
        #   querying for objects via API or the dashboard.
        #
        #   Keys are strings with a maximum length of 64 characters. Values are strings with
        #   a maximum length of 512 characters.
        #
        #   @return [Hash{Symbol=>String}, nil]
        optional :metadata, OpenAI::Internal::Type::HashOf[String], nil?: true

        # @!attribute modalities
        #   The set of modalities the model used to respond. If there are multiple
        #   modalities, the model will pick one, for example if `modalities` is
        #   `["text", "audio"]`, the model could be responding in either text or audio.
        #
        #   @return [Array<Symbol, OpenAI::Models::Realtime::RealtimeResponse::Modality>, nil]
        optional :modalities,
                 -> { OpenAI::Internal::Type::ArrayOf[enum: OpenAI::Realtime::RealtimeResponse::Modality] }

        # @!attribute object
        #   The object type, must be `realtime.response`.
        #
        #   @return [Symbol, OpenAI::Models::Realtime::RealtimeResponse::Object, nil]
        optional :object, enum: -> { OpenAI::Realtime::RealtimeResponse::Object }

        # @!attribute output
        #   The list of output items generated by the response.
        #
        #   @return [Array<OpenAI::Models::Realtime::RealtimeConversationItemSystemMessage, OpenAI::Models::Realtime::RealtimeConversationItemUserMessage, OpenAI::Models::Realtime::RealtimeConversationItemAssistantMessage, OpenAI::Models::Realtime::RealtimeConversationItemFunctionCall, OpenAI::Models::Realtime::RealtimeConversationItemFunctionCallOutput, OpenAI::Models::Realtime::RealtimeMcpApprovalResponse, OpenAI::Models::Realtime::RealtimeMcpListTools, OpenAI::Models::Realtime::RealtimeMcpToolCall, OpenAI::Models::Realtime::RealtimeMcpApprovalRequest>, nil]
        optional :output, -> { OpenAI::Internal::Type::ArrayOf[union: OpenAI::Realtime::ConversationItem] }

        # @!attribute output_audio_format
        #   The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
        #
        #   @return [Symbol, OpenAI::Models::Realtime::RealtimeResponse::OutputAudioFormat, nil]
        optional :output_audio_format, enum: -> { OpenAI::Realtime::RealtimeResponse::OutputAudioFormat }

        # @!attribute status
        #   The final status of the response (`completed`, `cancelled`, `failed`, or
        #   `incomplete`, `in_progress`).
        #
        #   @return [Symbol, OpenAI::Models::Realtime::RealtimeResponse::Status, nil]
        optional :status, enum: -> { OpenAI::Realtime::RealtimeResponse::Status }

        # @!attribute status_details
        #   Additional details about the status.
        #
        #   @return [OpenAI::Models::Realtime::RealtimeResponseStatus, nil]
        optional :status_details, -> { OpenAI::Realtime::RealtimeResponseStatus }

        # @!attribute temperature
        #   Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
        #
        #   @return [Float, nil]
        optional :temperature, Float

        # @!attribute usage
        #   Usage statistics for the Response, this will correspond to billing. A Realtime
        #   API session will maintain a conversation context and append new Items to the
        #   Conversation, thus output from previous turns (text and audio tokens) will
        #   become the input for later turns.
        #
        #   @return [OpenAI::Models::Realtime::RealtimeResponseUsage, nil]
        optional :usage, -> { OpenAI::Realtime::RealtimeResponseUsage }

        # @!attribute voice
        #   The voice the model used to respond. Current voice options are `alloy`, `ash`,
        #   `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.
        #
        #   @return [String, Symbol, OpenAI::Models::Realtime::RealtimeResponse::Voice, nil]
        optional :voice, union: -> { OpenAI::Realtime::RealtimeResponse::Voice }

        # @!method initialize(id: nil, conversation_id: nil, max_output_tokens: nil, metadata: nil, modalities: nil, object: nil, output: nil, output_audio_format: nil, status: nil, status_details: nil, temperature: nil, usage: nil, voice: nil)
        #   Some parameter documentations has been truncated, see
        #   {OpenAI::Models::Realtime::RealtimeResponse} for more details.
        #
        #   The response resource.
        #
        #   @param id [String] The unique ID of the response.
        #
        #   @param conversation_id [String] Which conversation the response is added to, determined by the `conversation`
        #
        #   @param max_output_tokens [Integer, Symbol, :inf] Maximum number of output tokens for a single assistant response,
        #
        #   @param metadata [Hash{Symbol=>String}, nil] Set of 16 key-value pairs that can be attached to an object. This can be
        #
        #   @param modalities [Array<Symbol, OpenAI::Models::Realtime::RealtimeResponse::Modality>] The set of modalities the model used to respond. If there are multiple modalitie
        #
        #   @param object [Symbol, OpenAI::Models::Realtime::RealtimeResponse::Object] The object type, must be `realtime.response`.
        #
        #   @param output [Array<OpenAI::Models::Realtime::RealtimeConversationItemSystemMessage, OpenAI::Models::Realtime::RealtimeConversationItemUserMessage, OpenAI::Models::Realtime::RealtimeConversationItemAssistantMessage, OpenAI::Models::Realtime::RealtimeConversationItemFunctionCall, OpenAI::Models::Realtime::RealtimeConversationItemFunctionCallOutput, OpenAI::Models::Realtime::RealtimeMcpApprovalResponse, OpenAI::Models::Realtime::RealtimeMcpListTools, OpenAI::Models::Realtime::RealtimeMcpToolCall, OpenAI::Models::Realtime::RealtimeMcpApprovalRequest>] The list of output items generated by the response.
        #
        #   @param output_audio_format [Symbol, OpenAI::Models::Realtime::RealtimeResponse::OutputAudioFormat] The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
        #
        #   @param status [Symbol, OpenAI::Models::Realtime::RealtimeResponse::Status] The final status of the response (`completed`, `cancelled`, `failed`, or
        #
        #   @param status_details [OpenAI::Models::Realtime::RealtimeResponseStatus] Additional details about the status.
        #
        #   @param temperature [Float] Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
        #
        #   @param usage [OpenAI::Models::Realtime::RealtimeResponseUsage] Usage statistics for the Response, this will correspond to billing. A
        #
        #   @param voice [String, Symbol, OpenAI::Models::Realtime::RealtimeResponse::Voice] The voice the model used to respond.

        # Maximum number of output tokens for a single assistant response, inclusive of
        # tool calls, that was used in this response.
        #
        # @see OpenAI::Models::Realtime::RealtimeResponse#max_output_tokens
        module MaxOutputTokens
          extend OpenAI::Internal::Type::Union

          variant Integer

          variant const: :inf

          # @!method self.variants
          #   @return [Array(Integer, Symbol, :inf)]
        end

        module Modality
          extend OpenAI::Internal::Type::Enum

          TEXT = :text
          AUDIO = :audio

          # @!method self.values
          #   @return [Array<Symbol>]
        end

        # The object type, must be `realtime.response`.
        #
        # @see OpenAI::Models::Realtime::RealtimeResponse#object
        module Object
          extend OpenAI::Internal::Type::Enum

          REALTIME_RESPONSE = :"realtime.response"

          # @!method self.values
          #   @return [Array<Symbol>]
        end

        # The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
        #
        # @see OpenAI::Models::Realtime::RealtimeResponse#output_audio_format
        module OutputAudioFormat
          extend OpenAI::Internal::Type::Enum

          PCM16 = :pcm16
          G711_ULAW = :g711_ulaw
          G711_ALAW = :g711_alaw

          # @!method self.values
          #   @return [Array<Symbol>]
        end

        # The final status of the response (`completed`, `cancelled`, `failed`, or
        # `incomplete`, `in_progress`).
        #
        # @see OpenAI::Models::Realtime::RealtimeResponse#status
        module Status
          extend OpenAI::Internal::Type::Enum

          COMPLETED = :completed
          CANCELLED = :cancelled
          FAILED = :failed
          INCOMPLETE = :incomplete
          IN_PROGRESS = :in_progress

          # @!method self.values
          #   @return [Array<Symbol>]
        end

        # The voice the model used to respond. Current voice options are `alloy`, `ash`,
        # `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.
        #
        # @see OpenAI::Models::Realtime::RealtimeResponse#voice
        module Voice
          extend OpenAI::Internal::Type::Union

          variant String

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::ALLOY }

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::ASH }

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::BALLAD }

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::CORAL }

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::ECHO }

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::SAGE }

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::SHIMMER }

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::VERSE }

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::MARIN }

          variant const: -> { OpenAI::Models::Realtime::RealtimeResponse::Voice::CEDAR }

          # @!method self.variants
          #   @return [Array(String, Symbol)]

          define_sorbet_constant!(:Variants) do
            T.type_alias { T.any(String, OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol) }
          end

          # @!group

          ALLOY = :alloy
          ASH = :ash
          BALLAD = :ballad
          CORAL = :coral
          ECHO = :echo
          SAGE = :sage
          SHIMMER = :shimmer
          VERSE = :verse
          MARIN = :marin
          CEDAR = :cedar

          # @!endgroup
        end
      end
    end
  end
end
