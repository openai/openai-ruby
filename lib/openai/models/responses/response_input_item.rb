# frozen_string_literal: true

module OpenAI
  module Models
    module Responses
      # A message input to the model with a role indicating instruction following
      # hierarchy. Instructions given with the `developer` or `system` role take
      # precedence over instructions given with the `user` role. Messages with the
      # `assistant` role are presumed to have been generated by the model in previous
      # interactions.
      module ResponseInputItem
        extend OpenAI::Internal::Type::Union

        discriminator :type

        # A message input to the model with a role indicating instruction following
        # hierarchy. Instructions given with the `developer` or `system` role take
        # precedence over instructions given with the `user` role. Messages with the
        # `assistant` role are presumed to have been generated by the model in previous
        # interactions.
        variant :message, -> { OpenAI::Responses::EasyInputMessage }

        # A message input to the model with a role indicating instruction following
        # hierarchy. Instructions given with the `developer` or `system` role take
        # precedence over instructions given with the `user` role.
        variant :message, -> { OpenAI::Responses::ResponseInputItem::Message }

        # An output message from the model.
        variant :message, -> { OpenAI::Responses::ResponseOutputMessage }

        # The results of a file search tool call. See the
        # [file search guide](https://platform.openai.com/docs/guides/tools-file-search) for more information.
        variant :file_search_call, -> { OpenAI::Responses::ResponseFileSearchToolCall }

        # A tool call to a computer use tool. See the
        # [computer use guide](https://platform.openai.com/docs/guides/tools-computer-use) for more information.
        variant :computer_call, -> { OpenAI::Responses::ResponseComputerToolCall }

        # The output of a computer tool call.
        variant :computer_call_output, -> { OpenAI::Responses::ResponseInputItem::ComputerCallOutput }

        # The results of a web search tool call. See the
        # [web search guide](https://platform.openai.com/docs/guides/tools-web-search) for more information.
        variant :web_search_call, -> { OpenAI::Responses::ResponseFunctionWebSearch }

        # A tool call to run a function. See the
        # [function calling guide](https://platform.openai.com/docs/guides/function-calling) for more information.
        variant :function_call, -> { OpenAI::Responses::ResponseFunctionToolCall }

        # The output of a function tool call.
        variant :function_call_output, -> { OpenAI::Responses::ResponseInputItem::FunctionCallOutput }

        # A description of the chain of thought used by a reasoning model while generating
        # a response. Be sure to include these items in your `input` to the Responses API
        # for subsequent turns of a conversation if you are manually
        # [managing context](https://platform.openai.com/docs/guides/conversation-state).
        variant :reasoning, -> { OpenAI::Responses::ResponseReasoningItem }

        # An image generation request made by the model.
        variant :image_generation_call, -> { OpenAI::Responses::ResponseInputItem::ImageGenerationCall }

        # A tool call to run code.
        variant :code_interpreter_call, -> { OpenAI::Responses::ResponseCodeInterpreterToolCall }

        # A tool call to run a command on the local shell.
        variant :local_shell_call, -> { OpenAI::Responses::ResponseInputItem::LocalShellCall }

        # The output of a local shell tool call.
        variant :local_shell_call_output, -> { OpenAI::Responses::ResponseInputItem::LocalShellCallOutput }

        # A list of tools available on an MCP server.
        variant :mcp_list_tools, -> { OpenAI::Responses::ResponseInputItem::McpListTools }

        # A request for human approval of a tool invocation.
        variant :mcp_approval_request, -> { OpenAI::Responses::ResponseInputItem::McpApprovalRequest }

        # A response to an MCP approval request.
        variant :mcp_approval_response, -> { OpenAI::Responses::ResponseInputItem::McpApprovalResponse }

        # An invocation of a tool on an MCP server.
        variant :mcp_call, -> { OpenAI::Responses::ResponseInputItem::McpCall }

        # An internal identifier for an item to reference.
        variant :item_reference, -> { OpenAI::Responses::ResponseInputItem::ItemReference }

        class Message < OpenAI::Internal::Type::BaseModel
          # @!attribute content
          #   A list of one or many input items to the model, containing different content
          #   types.
          #
          #   @return [Array<OpenAI::Responses::ResponseInputText, OpenAI::Responses::ResponseInputImage, OpenAI::Responses::ResponseInputFile>]
          required :content,
                   -> {
                     OpenAI::Internal::Type::ArrayOf[union: OpenAI::Responses::ResponseInputContent]
                   }

          # @!attribute role
          #   The role of the message input. One of `user`, `system`, or `developer`.
          #
          #   @return [Symbol, OpenAI::Responses::ResponseInputItem::Message::Role]
          required :role, enum: -> { OpenAI::Responses::ResponseInputItem::Message::Role }

          # @!attribute status
          #   The status of item. One of `in_progress`, `completed`, or `incomplete`.
          #   Populated when items are returned via API.
          #
          #   @return [Symbol, OpenAI::Responses::ResponseInputItem::Message::Status, nil]
          optional :status, enum: -> { OpenAI::Responses::ResponseInputItem::Message::Status }

          # @!attribute type
          #   The type of the message input. Always set to `message`.
          #
          #   @return [Symbol, OpenAI::Responses::ResponseInputItem::Message::Type, nil]
          optional :type, enum: -> { OpenAI::Responses::ResponseInputItem::Message::Type }

          # @!method initialize(content:, role:, status: nil, type: nil)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::Message} for more details.
          #
          #   A message input to the model with a role indicating instruction following
          #   hierarchy. Instructions given with the `developer` or `system` role take
          #   precedence over instructions given with the `user` role.
          #
          #   @param content [Array<OpenAI::Responses::ResponseInputText, OpenAI::Responses::ResponseInputImage, OpenAI::Responses::ResponseInputFile>] A list of one or many input items to the model, containing different content
          #
          #   @param role [Symbol, OpenAI::Responses::ResponseInputItem::Message::Role] The role of the message input. One of `user`, `system`, or `developer`.
          #
          #   @param status [Symbol, OpenAI::Responses::ResponseInputItem::Message::Status] The status of item. One of `in_progress`, `completed`, or
          #
          #   @param type [Symbol, OpenAI::Responses::ResponseInputItem::Message::Type] The type of the message input. Always set to `message`.

          # The role of the message input. One of `user`, `system`, or `developer`.
          #
          # @see OpenAI::Responses::ResponseInputItem::Message#role
          module Role
            extend OpenAI::Internal::Type::Enum

            USER = :user
            SYSTEM = :system
            DEVELOPER = :developer

            # @!method self.values
            #   @return [Array<Symbol>]
          end

          # The status of item. One of `in_progress`, `completed`, or `incomplete`.
          # Populated when items are returned via API.
          #
          # @see OpenAI::Responses::ResponseInputItem::Message#status
          module Status
            extend OpenAI::Internal::Type::Enum

            IN_PROGRESS = :in_progress
            COMPLETED = :completed
            INCOMPLETE = :incomplete

            # @!method self.values
            #   @return [Array<Symbol>]
          end

          # The type of the message input. Always set to `message`.
          #
          # @see OpenAI::Responses::ResponseInputItem::Message#type
          module Type
            extend OpenAI::Internal::Type::Enum

            MESSAGE = :message

            # @!method self.values
            #   @return [Array<Symbol>]
          end
        end

        class ComputerCallOutput < OpenAI::Internal::Type::BaseModel
          # @!attribute call_id
          #   The ID of the computer tool call that produced the output.
          #
          #   @return [String]
          required :call_id, String

          # @!attribute output
          #   A computer screenshot image used with the computer use tool.
          #
          #   @return [OpenAI::Responses::ResponseComputerToolCallOutputScreenshot]
          required :output, -> { OpenAI::Responses::ResponseComputerToolCallOutputScreenshot }

          # @!attribute type
          #   The type of the computer tool call output. Always `computer_call_output`.
          #
          #   @return [Symbol, :computer_call_output]
          required :type, const: :computer_call_output

          # @!attribute id
          #   The ID of the computer tool call output.
          #
          #   @return [String, nil]
          optional :id, String, nil?: true

          # @!attribute acknowledged_safety_checks
          #   The safety checks reported by the API that have been acknowledged by the
          #   developer.
          #
          #   @return [Array<OpenAI::Responses::ResponseInputItem::ComputerCallOutput::AcknowledgedSafetyCheck>, nil]
          optional :acknowledged_safety_checks,
                   -> {
                     OpenAI::Internal::Type::ArrayOf[OpenAI::Responses::ResponseInputItem::ComputerCallOutput::AcknowledgedSafetyCheck]
                   },
                   nil?: true

          # @!attribute status
          #   The status of the message input. One of `in_progress`, `completed`, or
          #   `incomplete`. Populated when input items are returned via API.
          #
          #   @return [Symbol, OpenAI::Responses::ResponseInputItem::ComputerCallOutput::Status, nil]
          optional :status,
                   enum: -> { OpenAI::Responses::ResponseInputItem::ComputerCallOutput::Status },
                   nil?: true

          # @!method initialize(call_id:, output:, id: nil, acknowledged_safety_checks: nil, status: nil, type: :computer_call_output)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::ComputerCallOutput} for more details.
          #
          #   The output of a computer tool call.
          #
          #   @param call_id [String] The ID of the computer tool call that produced the output.
          #
          #   @param output [OpenAI::Responses::ResponseComputerToolCallOutputScreenshot] A computer screenshot image used with the computer use tool.
          #
          #   @param id [String, nil] The ID of the computer tool call output.
          #
          #   @param acknowledged_safety_checks [Array<OpenAI::Responses::ResponseInputItem::ComputerCallOutput::AcknowledgedSafetyCheck>, nil] The safety checks reported by the API that have been acknowledged by the develop
          #
          #   @param status [Symbol, OpenAI::Responses::ResponseInputItem::ComputerCallOutput::Status, nil] The status of the message input. One of `in_progress`, `completed`, or `incomple
          #
          #   @param type [Symbol, :computer_call_output] The type of the computer tool call output. Always `computer_call_output`.

          class AcknowledgedSafetyCheck < OpenAI::Internal::Type::BaseModel
            # @!attribute id
            #   The ID of the pending safety check.
            #
            #   @return [String]
            required :id, String

            # @!attribute code
            #   The type of the pending safety check.
            #
            #   @return [String, nil]
            optional :code, String, nil?: true

            # @!attribute message
            #   Details about the pending safety check.
            #
            #   @return [String, nil]
            optional :message, String, nil?: true

            # @!method initialize(id:, code: nil, message: nil)
            #   A pending safety check for the computer call.
            #
            #   @param id [String] The ID of the pending safety check.
            #
            #   @param code [String, nil] The type of the pending safety check.
            #
            #   @param message [String, nil] Details about the pending safety check.
          end

          # The status of the message input. One of `in_progress`, `completed`, or
          # `incomplete`. Populated when input items are returned via API.
          #
          # @see OpenAI::Responses::ResponseInputItem::ComputerCallOutput#status
          module Status
            extend OpenAI::Internal::Type::Enum

            IN_PROGRESS = :in_progress
            COMPLETED = :completed
            INCOMPLETE = :incomplete

            # @!method self.values
            #   @return [Array<Symbol>]
          end
        end

        class FunctionCallOutput < OpenAI::Internal::Type::BaseModel
          # @!attribute call_id
          #   The unique ID of the function tool call generated by the model.
          #
          #   @return [String]
          required :call_id, String

          # @!attribute output
          #   A JSON string of the output of the function tool call.
          #
          #   @return [String]
          required :output, String

          # @!attribute type
          #   The type of the function tool call output. Always `function_call_output`.
          #
          #   @return [Symbol, :function_call_output]
          required :type, const: :function_call_output

          # @!attribute id
          #   The unique ID of the function tool call output. Populated when this item is
          #   returned via API.
          #
          #   @return [String, nil]
          optional :id, String, nil?: true

          # @!attribute status
          #   The status of the item. One of `in_progress`, `completed`, or `incomplete`.
          #   Populated when items are returned via API.
          #
          #   @return [Symbol, OpenAI::Responses::ResponseInputItem::FunctionCallOutput::Status, nil]
          optional :status,
                   enum: -> { OpenAI::Responses::ResponseInputItem::FunctionCallOutput::Status },
                   nil?: true

          # @!method initialize(call_id:, output:, id: nil, status: nil, type: :function_call_output)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::FunctionCallOutput} for more details.
          #
          #   The output of a function tool call.
          #
          #   @param call_id [String] The unique ID of the function tool call generated by the model.
          #
          #   @param output [String] A JSON string of the output of the function tool call.
          #
          #   @param id [String, nil] The unique ID of the function tool call output. Populated when this item is retu
          #
          #   @param status [Symbol, OpenAI::Responses::ResponseInputItem::FunctionCallOutput::Status, nil] The status of the item. One of `in_progress`, `completed`, or `incomplete`. Popu
          #
          #   @param type [Symbol, :function_call_output] The type of the function tool call output. Always `function_call_output`.

          # The status of the item. One of `in_progress`, `completed`, or `incomplete`.
          # Populated when items are returned via API.
          #
          # @see OpenAI::Responses::ResponseInputItem::FunctionCallOutput#status
          module Status
            extend OpenAI::Internal::Type::Enum

            IN_PROGRESS = :in_progress
            COMPLETED = :completed
            INCOMPLETE = :incomplete

            # @!method self.values
            #   @return [Array<Symbol>]
          end
        end

        class ImageGenerationCall < OpenAI::Internal::Type::BaseModel
          # @!attribute id
          #   The unique ID of the image generation call.
          #
          #   @return [String]
          required :id, String

          # @!attribute result
          #   The generated image encoded in base64.
          #
          #   @return [String, nil]
          required :result, String, nil?: true

          # @!attribute status
          #   The status of the image generation call.
          #
          #   @return [Symbol, OpenAI::Responses::ResponseInputItem::ImageGenerationCall::Status]
          required :status, enum: -> { OpenAI::Responses::ResponseInputItem::ImageGenerationCall::Status }

          # @!attribute type
          #   The type of the image generation call. Always `image_generation_call`.
          #
          #   @return [Symbol, :image_generation_call]
          required :type, const: :image_generation_call

          # @!method initialize(id:, result:, status:, type: :image_generation_call)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::ImageGenerationCall} for more details.
          #
          #   An image generation request made by the model.
          #
          #   @param id [String] The unique ID of the image generation call.
          #
          #   @param result [String, nil] The generated image encoded in base64.
          #
          #   @param status [Symbol, OpenAI::Responses::ResponseInputItem::ImageGenerationCall::Status] The status of the image generation call.
          #
          #   @param type [Symbol, :image_generation_call] The type of the image generation call. Always `image_generation_call`.

          # The status of the image generation call.
          #
          # @see OpenAI::Responses::ResponseInputItem::ImageGenerationCall#status
          module Status
            extend OpenAI::Internal::Type::Enum

            IN_PROGRESS = :in_progress
            COMPLETED = :completed
            GENERATING = :generating
            FAILED = :failed

            # @!method self.values
            #   @return [Array<Symbol>]
          end
        end

        class LocalShellCall < OpenAI::Internal::Type::BaseModel
          # @!attribute id
          #   The unique ID of the local shell call.
          #
          #   @return [String]
          required :id, String

          # @!attribute action
          #   Execute a shell command on the server.
          #
          #   @return [OpenAI::Responses::ResponseInputItem::LocalShellCall::Action]
          required :action, -> { OpenAI::Responses::ResponseInputItem::LocalShellCall::Action }

          # @!attribute call_id
          #   The unique ID of the local shell tool call generated by the model.
          #
          #   @return [String]
          required :call_id, String

          # @!attribute status
          #   The status of the local shell call.
          #
          #   @return [Symbol, OpenAI::Responses::ResponseInputItem::LocalShellCall::Status]
          required :status, enum: -> { OpenAI::Responses::ResponseInputItem::LocalShellCall::Status }

          # @!attribute type
          #   The type of the local shell call. Always `local_shell_call`.
          #
          #   @return [Symbol, :local_shell_call]
          required :type, const: :local_shell_call

          # @!method initialize(id:, action:, call_id:, status:, type: :local_shell_call)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::LocalShellCall} for more details.
          #
          #   A tool call to run a command on the local shell.
          #
          #   @param id [String] The unique ID of the local shell call.
          #
          #   @param action [OpenAI::Responses::ResponseInputItem::LocalShellCall::Action] Execute a shell command on the server.
          #
          #   @param call_id [String] The unique ID of the local shell tool call generated by the model.
          #
          #   @param status [Symbol, OpenAI::Responses::ResponseInputItem::LocalShellCall::Status] The status of the local shell call.
          #
          #   @param type [Symbol, :local_shell_call] The type of the local shell call. Always `local_shell_call`.

          # @see OpenAI::Responses::ResponseInputItem::LocalShellCall#action
          class Action < OpenAI::Internal::Type::BaseModel
            # @!attribute command
            #   The command to run.
            #
            #   @return [Array<String>]
            required :command, OpenAI::Internal::Type::ArrayOf[String]

            # @!attribute env
            #   Environment variables to set for the command.
            #
            #   @return [Hash{Symbol=>String}]
            required :env, OpenAI::Internal::Type::HashOf[String]

            # @!attribute type
            #   The type of the local shell action. Always `exec`.
            #
            #   @return [Symbol, :exec]
            required :type, const: :exec

            # @!attribute timeout_ms
            #   Optional timeout in milliseconds for the command.
            #
            #   @return [Integer, nil]
            optional :timeout_ms, Integer, nil?: true

            # @!attribute user
            #   Optional user to run the command as.
            #
            #   @return [String, nil]
            optional :user, String, nil?: true

            # @!attribute working_directory
            #   Optional working directory to run the command in.
            #
            #   @return [String, nil]
            optional :working_directory, String, nil?: true

            # @!method initialize(command:, env:, timeout_ms: nil, user: nil, working_directory: nil, type: :exec)
            #   Some parameter documentations has been truncated, see
            #   {OpenAI::Responses::ResponseInputItem::LocalShellCall::Action} for more details.
            #
            #   Execute a shell command on the server.
            #
            #   @param command [Array<String>] The command to run.
            #
            #   @param env [Hash{Symbol=>String}] Environment variables to set for the command.
            #
            #   @param timeout_ms [Integer, nil] Optional timeout in milliseconds for the command.
            #
            #   @param user [String, nil] Optional user to run the command as.
            #
            #   @param working_directory [String, nil] Optional working directory to run the command in.
            #
            #   @param type [Symbol, :exec] The type of the local shell action. Always `exec`.
          end

          # The status of the local shell call.
          #
          # @see OpenAI::Responses::ResponseInputItem::LocalShellCall#status
          module Status
            extend OpenAI::Internal::Type::Enum

            IN_PROGRESS = :in_progress
            COMPLETED = :completed
            INCOMPLETE = :incomplete

            # @!method self.values
            #   @return [Array<Symbol>]
          end
        end

        class LocalShellCallOutput < OpenAI::Internal::Type::BaseModel
          # @!attribute id
          #   The unique ID of the local shell tool call generated by the model.
          #
          #   @return [String]
          required :id, String

          # @!attribute output
          #   A JSON string of the output of the local shell tool call.
          #
          #   @return [String]
          required :output, String

          # @!attribute type
          #   The type of the local shell tool call output. Always `local_shell_call_output`.
          #
          #   @return [Symbol, :local_shell_call_output]
          required :type, const: :local_shell_call_output

          # @!attribute status
          #   The status of the item. One of `in_progress`, `completed`, or `incomplete`.
          #
          #   @return [Symbol, OpenAI::Responses::ResponseInputItem::LocalShellCallOutput::Status, nil]
          optional :status,
                   enum: -> { OpenAI::Responses::ResponseInputItem::LocalShellCallOutput::Status },
                   nil?: true

          # @!method initialize(id:, output:, status: nil, type: :local_shell_call_output)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::LocalShellCallOutput} for more details.
          #
          #   The output of a local shell tool call.
          #
          #   @param id [String] The unique ID of the local shell tool call generated by the model.
          #
          #   @param output [String] A JSON string of the output of the local shell tool call.
          #
          #   @param status [Symbol, OpenAI::Responses::ResponseInputItem::LocalShellCallOutput::Status, nil] The status of the item. One of `in_progress`, `completed`, or `incomplete`.
          #
          #   @param type [Symbol, :local_shell_call_output] The type of the local shell tool call output. Always `local_shell_call_output`.

          # The status of the item. One of `in_progress`, `completed`, or `incomplete`.
          #
          # @see OpenAI::Responses::ResponseInputItem::LocalShellCallOutput#status
          module Status
            extend OpenAI::Internal::Type::Enum

            IN_PROGRESS = :in_progress
            COMPLETED = :completed
            INCOMPLETE = :incomplete

            # @!method self.values
            #   @return [Array<Symbol>]
          end
        end

        class McpListTools < OpenAI::Internal::Type::BaseModel
          # @!attribute id
          #   The unique ID of the list.
          #
          #   @return [String]
          required :id, String

          # @!attribute server_label
          #   The label of the MCP server.
          #
          #   @return [String]
          required :server_label, String

          # @!attribute tools
          #   The tools available on the server.
          #
          #   @return [Array<OpenAI::Responses::ResponseInputItem::McpListTools::Tool>]
          required :tools,
                   -> {
                     OpenAI::Internal::Type::ArrayOf[OpenAI::Responses::ResponseInputItem::McpListTools::Tool]
                   }

          # @!attribute type
          #   The type of the item. Always `mcp_list_tools`.
          #
          #   @return [Symbol, :mcp_list_tools]
          required :type, const: :mcp_list_tools

          # @!attribute error
          #   Error message if the server could not list tools.
          #
          #   @return [String, nil]
          optional :error, String, nil?: true

          # @!method initialize(id:, server_label:, tools:, error: nil, type: :mcp_list_tools)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::McpListTools} for more details.
          #
          #   A list of tools available on an MCP server.
          #
          #   @param id [String] The unique ID of the list.
          #
          #   @param server_label [String] The label of the MCP server.
          #
          #   @param tools [Array<OpenAI::Responses::ResponseInputItem::McpListTools::Tool>] The tools available on the server.
          #
          #   @param error [String, nil] Error message if the server could not list tools.
          #
          #   @param type [Symbol, :mcp_list_tools] The type of the item. Always `mcp_list_tools`.

          class Tool < OpenAI::Internal::Type::BaseModel
            # @!attribute input_schema
            #   The JSON schema describing the tool's input.
            #
            #   @return [Object]
            required :input_schema, OpenAI::Internal::Type::Unknown

            # @!attribute name
            #   The name of the tool.
            #
            #   @return [String]
            required :name, String

            # @!attribute annotations
            #   Additional annotations about the tool.
            #
            #   @return [Object, nil]
            optional :annotations, OpenAI::Internal::Type::Unknown, nil?: true

            # @!attribute description
            #   The description of the tool.
            #
            #   @return [String, nil]
            optional :description, String, nil?: true

            # @!method initialize(input_schema:, name:, annotations: nil, description: nil)
            #   Some parameter documentations has been truncated, see
            #   {OpenAI::Responses::ResponseInputItem::McpListTools::Tool} for more details.
            #
            #   A tool available on an MCP server.
            #
            #   @param input_schema [Object] The JSON schema describing the tool's input.
            #
            #   @param name [String] The name of the tool.
            #
            #   @param annotations [Object, nil] Additional annotations about the tool.
            #
            #   @param description [String, nil] The description of the tool.
          end
        end

        class McpApprovalRequest < OpenAI::Internal::Type::BaseModel
          # @!attribute id
          #   The unique ID of the approval request.
          #
          #   @return [String]
          required :id, String

          # @!attribute arguments
          #   A JSON string of arguments for the tool.
          #
          #   @return [String]
          required :arguments, String

          # @!attribute name
          #   The name of the tool to run.
          #
          #   @return [String]
          required :name, String

          # @!attribute server_label
          #   The label of the MCP server making the request.
          #
          #   @return [String]
          required :server_label, String

          # @!attribute type
          #   The type of the item. Always `mcp_approval_request`.
          #
          #   @return [Symbol, :mcp_approval_request]
          required :type, const: :mcp_approval_request

          # @!method initialize(id:, arguments:, name:, server_label:, type: :mcp_approval_request)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::McpApprovalRequest} for more details.
          #
          #   A request for human approval of a tool invocation.
          #
          #   @param id [String] The unique ID of the approval request.
          #
          #   @param arguments [String] A JSON string of arguments for the tool.
          #
          #   @param name [String] The name of the tool to run.
          #
          #   @param server_label [String] The label of the MCP server making the request.
          #
          #   @param type [Symbol, :mcp_approval_request] The type of the item. Always `mcp_approval_request`.
        end

        class McpApprovalResponse < OpenAI::Internal::Type::BaseModel
          # @!attribute approval_request_id
          #   The ID of the approval request being answered.
          #
          #   @return [String]
          required :approval_request_id, String

          # @!attribute approve
          #   Whether the request was approved.
          #
          #   @return [Boolean]
          required :approve, OpenAI::Internal::Type::Boolean

          # @!attribute type
          #   The type of the item. Always `mcp_approval_response`.
          #
          #   @return [Symbol, :mcp_approval_response]
          required :type, const: :mcp_approval_response

          # @!attribute id
          #   The unique ID of the approval response
          #
          #   @return [String, nil]
          optional :id, String, nil?: true

          # @!attribute reason
          #   Optional reason for the decision.
          #
          #   @return [String, nil]
          optional :reason, String, nil?: true

          # @!method initialize(approval_request_id:, approve:, id: nil, reason: nil, type: :mcp_approval_response)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::McpApprovalResponse} for more details.
          #
          #   A response to an MCP approval request.
          #
          #   @param approval_request_id [String] The ID of the approval request being answered.
          #
          #   @param approve [Boolean] Whether the request was approved.
          #
          #   @param id [String, nil] The unique ID of the approval response
          #
          #   @param reason [String, nil] Optional reason for the decision.
          #
          #   @param type [Symbol, :mcp_approval_response] The type of the item. Always `mcp_approval_response`.
        end

        class McpCall < OpenAI::Internal::Type::BaseModel
          # @!attribute id
          #   The unique ID of the tool call.
          #
          #   @return [String]
          required :id, String

          # @!attribute arguments
          #   A JSON string of the arguments passed to the tool.
          #
          #   @return [String]
          required :arguments, String

          # @!attribute name
          #   The name of the tool that was run.
          #
          #   @return [String]
          required :name, String

          # @!attribute server_label
          #   The label of the MCP server running the tool.
          #
          #   @return [String]
          required :server_label, String

          # @!attribute type
          #   The type of the item. Always `mcp_call`.
          #
          #   @return [Symbol, :mcp_call]
          required :type, const: :mcp_call

          # @!attribute error
          #   The error from the tool call, if any.
          #
          #   @return [String, nil]
          optional :error, String, nil?: true

          # @!attribute output
          #   The output from the tool call.
          #
          #   @return [String, nil]
          optional :output, String, nil?: true

          # @!method initialize(id:, arguments:, name:, server_label:, error: nil, output: nil, type: :mcp_call)
          #   Some parameter documentations has been truncated, see
          #   {OpenAI::Responses::ResponseInputItem::McpCall} for more details.
          #
          #   An invocation of a tool on an MCP server.
          #
          #   @param id [String] The unique ID of the tool call.
          #
          #   @param arguments [String] A JSON string of the arguments passed to the tool.
          #
          #   @param name [String] The name of the tool that was run.
          #
          #   @param server_label [String] The label of the MCP server running the tool.
          #
          #   @param error [String, nil] The error from the tool call, if any.
          #
          #   @param output [String, nil] The output from the tool call.
          #
          #   @param type [Symbol, :mcp_call] The type of the item. Always `mcp_call`.
        end

        class ItemReference < OpenAI::Internal::Type::BaseModel
          # @!attribute id
          #   The ID of the item to reference.
          #
          #   @return [String]
          required :id, String

          # @!attribute type
          #   The type of item to reference. Always `item_reference`.
          #
          #   @return [Symbol, OpenAI::Responses::ResponseInputItem::ItemReference::Type, nil]
          optional :type, enum: -> { OpenAI::Responses::ResponseInputItem::ItemReference::Type }, nil?: true

          # @!method initialize(id:, type: nil)
          #   An internal identifier for an item to reference.
          #
          #   @param id [String] The ID of the item to reference.
          #
          #   @param type [Symbol, OpenAI::Responses::ResponseInputItem::ItemReference::Type, nil] The type of item to reference. Always `item_reference`.

          # The type of item to reference. Always `item_reference`.
          #
          # @see OpenAI::Responses::ResponseInputItem::ItemReference#type
          module Type
            extend OpenAI::Internal::Type::Enum

            ITEM_REFERENCE = :item_reference

            # @!method self.values
            #   @return [Array<Symbol>]
          end
        end

        # @!method self.variants
        #   @return [Array(OpenAI::Responses::EasyInputMessage, OpenAI::Responses::ResponseInputItem::Message, OpenAI::Responses::ResponseOutputMessage, OpenAI::Responses::ResponseFileSearchToolCall, OpenAI::Responses::ResponseComputerToolCall, OpenAI::Responses::ResponseInputItem::ComputerCallOutput, OpenAI::Responses::ResponseFunctionWebSearch, OpenAI::Responses::ResponseFunctionToolCall, OpenAI::Responses::ResponseInputItem::FunctionCallOutput, OpenAI::Responses::ResponseReasoningItem, OpenAI::Responses::ResponseInputItem::ImageGenerationCall, OpenAI::Responses::ResponseCodeInterpreterToolCall, OpenAI::Responses::ResponseInputItem::LocalShellCall, OpenAI::Responses::ResponseInputItem::LocalShellCallOutput, OpenAI::Responses::ResponseInputItem::McpListTools, OpenAI::Responses::ResponseInputItem::McpApprovalRequest, OpenAI::Responses::ResponseInputItem::McpApprovalResponse, OpenAI::Responses::ResponseInputItem::McpCall, OpenAI::Responses::ResponseInputItem::ItemReference)]
      end
    end
  end
end
