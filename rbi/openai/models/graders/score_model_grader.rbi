# typed: strong

module OpenAI
  module Models
    ScoreModelGrader = Graders::ScoreModelGrader

    module Graders
      class ScoreModelGrader < OpenAI::Internal::Type::BaseModel
        OrHash =
          T.type_alias do
            T.any(OpenAI::Graders::ScoreModelGrader, OpenAI::Internal::AnyHash)
          end

        # The input messages evaluated by the grader. Supports text, output text, input
        # image, and input audio content blocks, and may include template strings.
        sig { returns(T::Array[OpenAI::Graders::ScoreModelGrader::Input]) }
        attr_accessor :input

        # The model to use for the evaluation.
        sig { returns(String) }
        attr_accessor :model

        # The name of the grader.
        sig { returns(String) }
        attr_accessor :name

        # The object type, which is always `score_model`.
        sig { returns(Symbol) }
        attr_accessor :type

        # The range of the score. Defaults to `[0, 1]`.
        sig { returns(T.nilable(T::Array[Float])) }
        attr_reader :range

        sig { params(range: T::Array[Float]).void }
        attr_writer :range

        # The sampling parameters for the model.
        sig do
          returns(T.nilable(OpenAI::Graders::ScoreModelGrader::SamplingParams))
        end
        attr_reader :sampling_params

        sig do
          params(
            sampling_params:
              OpenAI::Graders::ScoreModelGrader::SamplingParams::OrHash
          ).void
        end
        attr_writer :sampling_params

        # A ScoreModelGrader object that uses a model to assign a score to the input.
        sig do
          params(
            input: T::Array[OpenAI::Graders::ScoreModelGrader::Input::OrHash],
            model: String,
            name: String,
            range: T::Array[Float],
            sampling_params:
              OpenAI::Graders::ScoreModelGrader::SamplingParams::OrHash,
            type: Symbol
          ).returns(T.attached_class)
        end
        def self.new(
          # The input messages evaluated by the grader. Supports text, output text, input
          # image, and input audio content blocks, and may include template strings.
          input:,
          # The model to use for the evaluation.
          model:,
          # The name of the grader.
          name:,
          # The range of the score. Defaults to `[0, 1]`.
          range: nil,
          # The sampling parameters for the model.
          sampling_params: nil,
          # The object type, which is always `score_model`.
          type: :score_model
        )
        end

        sig do
          override.returns(
            {
              input: T::Array[OpenAI::Graders::ScoreModelGrader::Input],
              model: String,
              name: String,
              type: Symbol,
              range: T::Array[Float],
              sampling_params: OpenAI::Graders::ScoreModelGrader::SamplingParams
            }
          )
        end
        def to_hash
        end

        class Input < OpenAI::Internal::Type::BaseModel
          OrHash =
            T.type_alias do
              T.any(
                OpenAI::Graders::ScoreModelGrader::Input,
                OpenAI::Internal::AnyHash
              )
            end

          # Inputs to the model - can contain template strings.
          sig do
            returns(
              T.any(
                String,
                OpenAI::Responses::ResponseInputText,
                OpenAI::Graders::ScoreModelGrader::Input::Content::OutputText,
                OpenAI::Graders::ScoreModelGrader::Input::Content::InputImage,
                OpenAI::Responses::ResponseInputAudio,
                T::Array[T.anything]
              )
            )
          end
          attr_accessor :content

          # The role of the message input. One of `user`, `assistant`, `system`, or
          # `developer`.
          sig do
            returns(OpenAI::Graders::ScoreModelGrader::Input::Role::OrSymbol)
          end
          attr_accessor :role

          # The type of the message input. Always `message`.
          sig do
            returns(
              T.nilable(
                OpenAI::Graders::ScoreModelGrader::Input::Type::OrSymbol
              )
            )
          end
          attr_reader :type

          sig do
            params(
              type: OpenAI::Graders::ScoreModelGrader::Input::Type::OrSymbol
            ).void
          end
          attr_writer :type

          # A message input to the model with a role indicating instruction following
          # hierarchy. Instructions given with the `developer` or `system` role take
          # precedence over instructions given with the `user` role. Messages with the
          # `assistant` role are presumed to have been generated by the model in previous
          # interactions.
          sig do
            params(
              content:
                T.any(
                  String,
                  OpenAI::Responses::ResponseInputText::OrHash,
                  OpenAI::Graders::ScoreModelGrader::Input::Content::OutputText::OrHash,
                  OpenAI::Graders::ScoreModelGrader::Input::Content::InputImage::OrHash,
                  OpenAI::Responses::ResponseInputAudio::OrHash,
                  T::Array[T.anything]
                ),
              role: OpenAI::Graders::ScoreModelGrader::Input::Role::OrSymbol,
              type: OpenAI::Graders::ScoreModelGrader::Input::Type::OrSymbol
            ).returns(T.attached_class)
          end
          def self.new(
            # Inputs to the model - can contain template strings.
            content:,
            # The role of the message input. One of `user`, `assistant`, `system`, or
            # `developer`.
            role:,
            # The type of the message input. Always `message`.
            type: nil
          )
          end

          sig do
            override.returns(
              {
                content:
                  T.any(
                    String,
                    OpenAI::Responses::ResponseInputText,
                    OpenAI::Graders::ScoreModelGrader::Input::Content::OutputText,
                    OpenAI::Graders::ScoreModelGrader::Input::Content::InputImage,
                    OpenAI::Responses::ResponseInputAudio,
                    T::Array[T.anything]
                  ),
                role: OpenAI::Graders::ScoreModelGrader::Input::Role::OrSymbol,
                type: OpenAI::Graders::ScoreModelGrader::Input::Type::OrSymbol
              }
            )
          end
          def to_hash
          end

          # Inputs to the model - can contain template strings.
          module Content
            extend OpenAI::Internal::Type::Union

            Variants =
              T.type_alias do
                T.any(
                  String,
                  OpenAI::Responses::ResponseInputText,
                  OpenAI::Graders::ScoreModelGrader::Input::Content::OutputText,
                  OpenAI::Graders::ScoreModelGrader::Input::Content::InputImage,
                  OpenAI::Responses::ResponseInputAudio,
                  T::Array[T.anything]
                )
              end

            class OutputText < OpenAI::Internal::Type::BaseModel
              OrHash =
                T.type_alias do
                  T.any(
                    OpenAI::Graders::ScoreModelGrader::Input::Content::OutputText,
                    OpenAI::Internal::AnyHash
                  )
                end

              # The text output from the model.
              sig { returns(String) }
              attr_accessor :text

              # The type of the output text. Always `output_text`.
              sig { returns(Symbol) }
              attr_accessor :type

              # A text output from the model.
              sig do
                params(text: String, type: Symbol).returns(T.attached_class)
              end
              def self.new(
                # The text output from the model.
                text:,
                # The type of the output text. Always `output_text`.
                type: :output_text
              )
              end

              sig { override.returns({ text: String, type: Symbol }) }
              def to_hash
              end
            end

            class InputImage < OpenAI::Internal::Type::BaseModel
              OrHash =
                T.type_alias do
                  T.any(
                    OpenAI::Graders::ScoreModelGrader::Input::Content::InputImage,
                    OpenAI::Internal::AnyHash
                  )
                end

              # The URL of the image input.
              sig { returns(String) }
              attr_accessor :image_url

              # The type of the image input. Always `input_image`.
              sig { returns(Symbol) }
              attr_accessor :type

              # The detail level of the image to be sent to the model. One of `high`, `low`, or
              # `auto`. Defaults to `auto`.
              sig { returns(T.nilable(String)) }
              attr_reader :detail

              sig { params(detail: String).void }
              attr_writer :detail

              # An image input to the model.
              sig do
                params(image_url: String, detail: String, type: Symbol).returns(
                  T.attached_class
                )
              end
              def self.new(
                # The URL of the image input.
                image_url:,
                # The detail level of the image to be sent to the model. One of `high`, `low`, or
                # `auto`. Defaults to `auto`.
                detail: nil,
                # The type of the image input. Always `input_image`.
                type: :input_image
              )
              end

              sig do
                override.returns(
                  { image_url: String, type: Symbol, detail: String }
                )
              end
              def to_hash
              end
            end

            sig do
              override.returns(
                T::Array[
                  OpenAI::Graders::ScoreModelGrader::Input::Content::Variants
                ]
              )
            end
            def self.variants
            end

            AnArrayOfInputTextInputImageAndInputAudioArray =
              T.let(
                OpenAI::Internal::Type::ArrayOf[
                  OpenAI::Internal::Type::Unknown
                ],
                OpenAI::Internal::Type::Converter
              )
          end

          # The role of the message input. One of `user`, `assistant`, `system`, or
          # `developer`.
          module Role
            extend OpenAI::Internal::Type::Enum

            TaggedSymbol =
              T.type_alias do
                T.all(Symbol, OpenAI::Graders::ScoreModelGrader::Input::Role)
              end
            OrSymbol = T.type_alias { T.any(Symbol, String) }

            USER =
              T.let(
                :user,
                OpenAI::Graders::ScoreModelGrader::Input::Role::TaggedSymbol
              )
            ASSISTANT =
              T.let(
                :assistant,
                OpenAI::Graders::ScoreModelGrader::Input::Role::TaggedSymbol
              )
            SYSTEM =
              T.let(
                :system,
                OpenAI::Graders::ScoreModelGrader::Input::Role::TaggedSymbol
              )
            DEVELOPER =
              T.let(
                :developer,
                OpenAI::Graders::ScoreModelGrader::Input::Role::TaggedSymbol
              )

            sig do
              override.returns(
                T::Array[
                  OpenAI::Graders::ScoreModelGrader::Input::Role::TaggedSymbol
                ]
              )
            end
            def self.values
            end
          end

          # The type of the message input. Always `message`.
          module Type
            extend OpenAI::Internal::Type::Enum

            TaggedSymbol =
              T.type_alias do
                T.all(Symbol, OpenAI::Graders::ScoreModelGrader::Input::Type)
              end
            OrSymbol = T.type_alias { T.any(Symbol, String) }

            MESSAGE =
              T.let(
                :message,
                OpenAI::Graders::ScoreModelGrader::Input::Type::TaggedSymbol
              )

            sig do
              override.returns(
                T::Array[
                  OpenAI::Graders::ScoreModelGrader::Input::Type::TaggedSymbol
                ]
              )
            end
            def self.values
            end
          end
        end

        class SamplingParams < OpenAI::Internal::Type::BaseModel
          OrHash =
            T.type_alias do
              T.any(
                OpenAI::Graders::ScoreModelGrader::SamplingParams,
                OpenAI::Internal::AnyHash
              )
            end

          # The maximum number of tokens the grader model may generate in its response.
          sig { returns(T.nilable(Integer)) }
          attr_accessor :max_completions_tokens

          # Constrains effort on reasoning for
          # [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently
          # supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.
          # Reducing reasoning effort can result in faster responses and fewer tokens used
          # on reasoning in a response.
          #
          # - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported
          #   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool
          #   calls are supported for all reasoning values in gpt-5.1.
          # - All models before `gpt-5.1` default to `medium` reasoning effort, and do not
          #   support `none`.
          # - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.
          # - `xhigh` is supported for all models after `gpt-5.1-codex-max`.
          sig { returns(T.nilable(OpenAI::ReasoningEffort::OrSymbol)) }
          attr_accessor :reasoning_effort

          # A seed value to initialize the randomness, during sampling.
          sig { returns(T.nilable(Integer)) }
          attr_accessor :seed

          # A higher temperature increases randomness in the outputs.
          sig { returns(T.nilable(Float)) }
          attr_accessor :temperature

          # An alternative to temperature for nucleus sampling; 1.0 includes all tokens.
          sig { returns(T.nilable(Float)) }
          attr_accessor :top_p

          # The sampling parameters for the model.
          sig do
            params(
              max_completions_tokens: T.nilable(Integer),
              reasoning_effort: T.nilable(OpenAI::ReasoningEffort::OrSymbol),
              seed: T.nilable(Integer),
              temperature: T.nilable(Float),
              top_p: T.nilable(Float)
            ).returns(T.attached_class)
          end
          def self.new(
            # The maximum number of tokens the grader model may generate in its response.
            max_completions_tokens: nil,
            # Constrains effort on reasoning for
            # [reasoning models](https://platform.openai.com/docs/guides/reasoning). Currently
            # supported values are `none`, `minimal`, `low`, `medium`, `high`, and `xhigh`.
            # Reducing reasoning effort can result in faster responses and fewer tokens used
            # on reasoning in a response.
            #
            # - `gpt-5.1` defaults to `none`, which does not perform reasoning. The supported
            #   reasoning values for `gpt-5.1` are `none`, `low`, `medium`, and `high`. Tool
            #   calls are supported for all reasoning values in gpt-5.1.
            # - All models before `gpt-5.1` default to `medium` reasoning effort, and do not
            #   support `none`.
            # - The `gpt-5-pro` model defaults to (and only supports) `high` reasoning effort.
            # - `xhigh` is supported for all models after `gpt-5.1-codex-max`.
            reasoning_effort: nil,
            # A seed value to initialize the randomness, during sampling.
            seed: nil,
            # A higher temperature increases randomness in the outputs.
            temperature: nil,
            # An alternative to temperature for nucleus sampling; 1.0 includes all tokens.
            top_p: nil
          )
          end

          sig do
            override.returns(
              {
                max_completions_tokens: T.nilable(Integer),
                reasoning_effort: T.nilable(OpenAI::ReasoningEffort::OrSymbol),
                seed: T.nilable(Integer),
                temperature: T.nilable(Float),
                top_p: T.nilable(Float)
              }
            )
          end
          def to_hash
          end
        end
      end
    end
  end
end
