# typed: strong

module OpenAI
  module Models
    module Realtime
      class RealtimeResponse < OpenAI::Internal::Type::BaseModel
        OrHash =
          T.type_alias do
            T.any(OpenAI::Realtime::RealtimeResponse, OpenAI::Internal::AnyHash)
          end

        # The unique ID of the response.
        sig { returns(T.nilable(String)) }
        attr_reader :id

        sig { params(id: String).void }
        attr_writer :id

        # Which conversation the response is added to, determined by the `conversation`
        # field in the `response.create` event. If `auto`, the response will be added to
        # the default conversation and the value of `conversation_id` will be an id like
        # `conv_1234`. If `none`, the response will not be added to any conversation and
        # the value of `conversation_id` will be `null`. If responses are being triggered
        # by server VAD, the response will be added to the default conversation, thus the
        # `conversation_id` will be an id like `conv_1234`.
        sig { returns(T.nilable(String)) }
        attr_reader :conversation_id

        sig { params(conversation_id: String).void }
        attr_writer :conversation_id

        # Maximum number of output tokens for a single assistant response, inclusive of
        # tool calls, that was used in this response.
        sig { returns(T.nilable(T.any(Integer, Symbol))) }
        attr_reader :max_output_tokens

        sig { params(max_output_tokens: T.any(Integer, Symbol)).void }
        attr_writer :max_output_tokens

        # Set of 16 key-value pairs that can be attached to an object. This can be useful
        # for storing additional information about the object in a structured format, and
        # querying for objects via API or the dashboard.
        #
        # Keys are strings with a maximum length of 64 characters. Values are strings with
        # a maximum length of 512 characters.
        sig { returns(T.nilable(T::Hash[Symbol, String])) }
        attr_accessor :metadata

        # The set of modalities the model used to respond. If there are multiple
        # modalities, the model will pick one, for example if `modalities` is
        # `["text", "audio"]`, the model could be responding in either text or audio.
        sig do
          returns(
            T.nilable(
              T::Array[OpenAI::Realtime::RealtimeResponse::Modality::OrSymbol]
            )
          )
        end
        attr_reader :modalities

        sig do
          params(
            modalities:
              T::Array[OpenAI::Realtime::RealtimeResponse::Modality::OrSymbol]
          ).void
        end
        attr_writer :modalities

        # The object type, must be `realtime.response`.
        sig do
          returns(
            T.nilable(OpenAI::Realtime::RealtimeResponse::Object::OrSymbol)
          )
        end
        attr_reader :object

        sig do
          params(
            object: OpenAI::Realtime::RealtimeResponse::Object::OrSymbol
          ).void
        end
        attr_writer :object

        # The list of output items generated by the response.
        sig do
          returns(
            T.nilable(
              T::Array[
                T.any(
                  OpenAI::Realtime::RealtimeConversationItemSystemMessage,
                  OpenAI::Realtime::RealtimeConversationItemUserMessage,
                  OpenAI::Realtime::RealtimeConversationItemAssistantMessage,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCall,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCallOutput,
                  OpenAI::Realtime::RealtimeMcpApprovalResponse,
                  OpenAI::Realtime::RealtimeMcpListTools,
                  OpenAI::Realtime::RealtimeMcpToolCall,
                  OpenAI::Realtime::RealtimeMcpApprovalRequest
                )
              ]
            )
          )
        end
        attr_reader :output

        sig do
          params(
            output:
              T::Array[
                T.any(
                  OpenAI::Realtime::RealtimeConversationItemSystemMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemUserMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemAssistantMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCall::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCallOutput::OrHash,
                  OpenAI::Realtime::RealtimeMcpApprovalResponse::OrHash,
                  OpenAI::Realtime::RealtimeMcpListTools::OrHash,
                  OpenAI::Realtime::RealtimeMcpToolCall::OrHash,
                  OpenAI::Realtime::RealtimeMcpApprovalRequest::OrHash
                )
              ]
          ).void
        end
        attr_writer :output

        # The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
        sig do
          returns(
            T.nilable(
              OpenAI::Realtime::RealtimeResponse::OutputAudioFormat::OrSymbol
            )
          )
        end
        attr_reader :output_audio_format

        sig do
          params(
            output_audio_format:
              OpenAI::Realtime::RealtimeResponse::OutputAudioFormat::OrSymbol
          ).void
        end
        attr_writer :output_audio_format

        # The final status of the response (`completed`, `cancelled`, `failed`, or
        # `incomplete`, `in_progress`).
        sig do
          returns(
            T.nilable(OpenAI::Realtime::RealtimeResponse::Status::OrSymbol)
          )
        end
        attr_reader :status

        sig do
          params(
            status: OpenAI::Realtime::RealtimeResponse::Status::OrSymbol
          ).void
        end
        attr_writer :status

        # Additional details about the status.
        sig { returns(T.nilable(OpenAI::Realtime::RealtimeResponseStatus)) }
        attr_reader :status_details

        sig do
          params(
            status_details: OpenAI::Realtime::RealtimeResponseStatus::OrHash
          ).void
        end
        attr_writer :status_details

        # Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
        sig { returns(T.nilable(Float)) }
        attr_reader :temperature

        sig { params(temperature: Float).void }
        attr_writer :temperature

        # Usage statistics for the Response, this will correspond to billing. A Realtime
        # API session will maintain a conversation context and append new Items to the
        # Conversation, thus output from previous turns (text and audio tokens) will
        # become the input for later turns.
        sig { returns(T.nilable(OpenAI::Realtime::RealtimeResponseUsage)) }
        attr_reader :usage

        sig do
          params(usage: OpenAI::Realtime::RealtimeResponseUsage::OrHash).void
        end
        attr_writer :usage

        # The voice the model used to respond. Current voice options are `alloy`, `ash`,
        # `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.
        sig do
          returns(
            T.nilable(
              T.any(String, OpenAI::Realtime::RealtimeResponse::Voice::OrSymbol)
            )
          )
        end
        attr_reader :voice

        sig do
          params(
            voice:
              T.any(String, OpenAI::Realtime::RealtimeResponse::Voice::OrSymbol)
          ).void
        end
        attr_writer :voice

        # The response resource.
        sig do
          params(
            id: String,
            conversation_id: String,
            max_output_tokens: T.any(Integer, Symbol),
            metadata: T.nilable(T::Hash[Symbol, String]),
            modalities:
              T::Array[OpenAI::Realtime::RealtimeResponse::Modality::OrSymbol],
            object: OpenAI::Realtime::RealtimeResponse::Object::OrSymbol,
            output:
              T::Array[
                T.any(
                  OpenAI::Realtime::RealtimeConversationItemSystemMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemUserMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemAssistantMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCall::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCallOutput::OrHash,
                  OpenAI::Realtime::RealtimeMcpApprovalResponse::OrHash,
                  OpenAI::Realtime::RealtimeMcpListTools::OrHash,
                  OpenAI::Realtime::RealtimeMcpToolCall::OrHash,
                  OpenAI::Realtime::RealtimeMcpApprovalRequest::OrHash
                )
              ],
            output_audio_format:
              OpenAI::Realtime::RealtimeResponse::OutputAudioFormat::OrSymbol,
            status: OpenAI::Realtime::RealtimeResponse::Status::OrSymbol,
            status_details: OpenAI::Realtime::RealtimeResponseStatus::OrHash,
            temperature: Float,
            usage: OpenAI::Realtime::RealtimeResponseUsage::OrHash,
            voice:
              T.any(String, OpenAI::Realtime::RealtimeResponse::Voice::OrSymbol)
          ).returns(T.attached_class)
        end
        def self.new(
          # The unique ID of the response.
          id: nil,
          # Which conversation the response is added to, determined by the `conversation`
          # field in the `response.create` event. If `auto`, the response will be added to
          # the default conversation and the value of `conversation_id` will be an id like
          # `conv_1234`. If `none`, the response will not be added to any conversation and
          # the value of `conversation_id` will be `null`. If responses are being triggered
          # by server VAD, the response will be added to the default conversation, thus the
          # `conversation_id` will be an id like `conv_1234`.
          conversation_id: nil,
          # Maximum number of output tokens for a single assistant response, inclusive of
          # tool calls, that was used in this response.
          max_output_tokens: nil,
          # Set of 16 key-value pairs that can be attached to an object. This can be useful
          # for storing additional information about the object in a structured format, and
          # querying for objects via API or the dashboard.
          #
          # Keys are strings with a maximum length of 64 characters. Values are strings with
          # a maximum length of 512 characters.
          metadata: nil,
          # The set of modalities the model used to respond. If there are multiple
          # modalities, the model will pick one, for example if `modalities` is
          # `["text", "audio"]`, the model could be responding in either text or audio.
          modalities: nil,
          # The object type, must be `realtime.response`.
          object: nil,
          # The list of output items generated by the response.
          output: nil,
          # The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
          output_audio_format: nil,
          # The final status of the response (`completed`, `cancelled`, `failed`, or
          # `incomplete`, `in_progress`).
          status: nil,
          # Additional details about the status.
          status_details: nil,
          # Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
          temperature: nil,
          # Usage statistics for the Response, this will correspond to billing. A Realtime
          # API session will maintain a conversation context and append new Items to the
          # Conversation, thus output from previous turns (text and audio tokens) will
          # become the input for later turns.
          usage: nil,
          # The voice the model used to respond. Current voice options are `alloy`, `ash`,
          # `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.
          voice: nil
        )
        end

        sig do
          override.returns(
            {
              id: String,
              conversation_id: String,
              max_output_tokens: T.any(Integer, Symbol),
              metadata: T.nilable(T::Hash[Symbol, String]),
              modalities:
                T::Array[
                  OpenAI::Realtime::RealtimeResponse::Modality::OrSymbol
                ],
              object: OpenAI::Realtime::RealtimeResponse::Object::OrSymbol,
              output:
                T::Array[
                  T.any(
                    OpenAI::Realtime::RealtimeConversationItemSystemMessage,
                    OpenAI::Realtime::RealtimeConversationItemUserMessage,
                    OpenAI::Realtime::RealtimeConversationItemAssistantMessage,
                    OpenAI::Realtime::RealtimeConversationItemFunctionCall,
                    OpenAI::Realtime::RealtimeConversationItemFunctionCallOutput,
                    OpenAI::Realtime::RealtimeMcpApprovalResponse,
                    OpenAI::Realtime::RealtimeMcpListTools,
                    OpenAI::Realtime::RealtimeMcpToolCall,
                    OpenAI::Realtime::RealtimeMcpApprovalRequest
                  )
                ],
              output_audio_format:
                OpenAI::Realtime::RealtimeResponse::OutputAudioFormat::OrSymbol,
              status: OpenAI::Realtime::RealtimeResponse::Status::OrSymbol,
              status_details: OpenAI::Realtime::RealtimeResponseStatus,
              temperature: Float,
              usage: OpenAI::Realtime::RealtimeResponseUsage,
              voice:
                T.any(
                  String,
                  OpenAI::Realtime::RealtimeResponse::Voice::OrSymbol
                )
            }
          )
        end
        def to_hash
        end

        # Maximum number of output tokens for a single assistant response, inclusive of
        # tool calls, that was used in this response.
        module MaxOutputTokens
          extend OpenAI::Internal::Type::Union

          Variants = T.type_alias { T.any(Integer, Symbol) }

          sig do
            override.returns(
              T::Array[
                OpenAI::Realtime::RealtimeResponse::MaxOutputTokens::Variants
              ]
            )
          end
          def self.variants
          end
        end

        module Modality
          extend OpenAI::Internal::Type::Enum

          TaggedSymbol =
            T.type_alias do
              T.all(Symbol, OpenAI::Realtime::RealtimeResponse::Modality)
            end
          OrSymbol = T.type_alias { T.any(Symbol, String) }

          TEXT =
            T.let(
              :text,
              OpenAI::Realtime::RealtimeResponse::Modality::TaggedSymbol
            )
          AUDIO =
            T.let(
              :audio,
              OpenAI::Realtime::RealtimeResponse::Modality::TaggedSymbol
            )

          sig do
            override.returns(
              T::Array[
                OpenAI::Realtime::RealtimeResponse::Modality::TaggedSymbol
              ]
            )
          end
          def self.values
          end
        end

        # The object type, must be `realtime.response`.
        module Object
          extend OpenAI::Internal::Type::Enum

          TaggedSymbol =
            T.type_alias do
              T.all(Symbol, OpenAI::Realtime::RealtimeResponse::Object)
            end
          OrSymbol = T.type_alias { T.any(Symbol, String) }

          REALTIME_RESPONSE =
            T.let(
              :"realtime.response",
              OpenAI::Realtime::RealtimeResponse::Object::TaggedSymbol
            )

          sig do
            override.returns(
              T::Array[OpenAI::Realtime::RealtimeResponse::Object::TaggedSymbol]
            )
          end
          def self.values
          end
        end

        # The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
        module OutputAudioFormat
          extend OpenAI::Internal::Type::Enum

          TaggedSymbol =
            T.type_alias do
              T.all(
                Symbol,
                OpenAI::Realtime::RealtimeResponse::OutputAudioFormat
              )
            end
          OrSymbol = T.type_alias { T.any(Symbol, String) }

          PCM16 =
            T.let(
              :pcm16,
              OpenAI::Realtime::RealtimeResponse::OutputAudioFormat::TaggedSymbol
            )
          G711_ULAW =
            T.let(
              :g711_ulaw,
              OpenAI::Realtime::RealtimeResponse::OutputAudioFormat::TaggedSymbol
            )
          G711_ALAW =
            T.let(
              :g711_alaw,
              OpenAI::Realtime::RealtimeResponse::OutputAudioFormat::TaggedSymbol
            )

          sig do
            override.returns(
              T::Array[
                OpenAI::Realtime::RealtimeResponse::OutputAudioFormat::TaggedSymbol
              ]
            )
          end
          def self.values
          end
        end

        # The final status of the response (`completed`, `cancelled`, `failed`, or
        # `incomplete`, `in_progress`).
        module Status
          extend OpenAI::Internal::Type::Enum

          TaggedSymbol =
            T.type_alias do
              T.all(Symbol, OpenAI::Realtime::RealtimeResponse::Status)
            end
          OrSymbol = T.type_alias { T.any(Symbol, String) }

          COMPLETED =
            T.let(
              :completed,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )
          CANCELLED =
            T.let(
              :cancelled,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )
          FAILED =
            T.let(
              :failed,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )
          INCOMPLETE =
            T.let(
              :incomplete,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )
          IN_PROGRESS =
            T.let(
              :in_progress,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )

          sig do
            override.returns(
              T::Array[OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol]
            )
          end
          def self.values
          end
        end

        # The voice the model used to respond. Current voice options are `alloy`, `ash`,
        # `ballad`, `coral`, `echo`, `sage`, `shimmer`, and `verse`.
        module Voice
          extend OpenAI::Internal::Type::Union

          Variants =
            T.type_alias do
              T.any(
                String,
                OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
              )
            end

          sig do
            override.returns(
              T::Array[OpenAI::Realtime::RealtimeResponse::Voice::Variants]
            )
          end
          def self.variants
          end

          TaggedSymbol =
            T.type_alias do
              T.all(Symbol, OpenAI::Realtime::RealtimeResponse::Voice)
            end
          OrSymbol = T.type_alias { T.any(Symbol, String) }

          ALLOY =
            T.let(
              :alloy,
              OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
            )
          ASH =
            T.let(:ash, OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol)
          BALLAD =
            T.let(
              :ballad,
              OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
            )
          CORAL =
            T.let(
              :coral,
              OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
            )
          ECHO =
            T.let(
              :echo,
              OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
            )
          SAGE =
            T.let(
              :sage,
              OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
            )
          SHIMMER =
            T.let(
              :shimmer,
              OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
            )
          VERSE =
            T.let(
              :verse,
              OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
            )
          MARIN =
            T.let(
              :marin,
              OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
            )
          CEDAR =
            T.let(
              :cedar,
              OpenAI::Realtime::RealtimeResponse::Voice::TaggedSymbol
            )
        end
      end
    end
  end
end
