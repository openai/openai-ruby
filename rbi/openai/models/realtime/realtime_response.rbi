# typed: strong

module OpenAI
  module Models
    module Realtime
      class RealtimeResponse < OpenAI::Internal::Type::BaseModel
        OrHash =
          T.type_alias do
            T.any(OpenAI::Realtime::RealtimeResponse, OpenAI::Internal::AnyHash)
          end

        # The unique ID of the response, will look like `resp_1234`.
        sig { returns(T.nilable(String)) }
        attr_reader :id

        sig { params(id: String).void }
        attr_writer :id

        # Configuration for audio output.
        sig { returns(T.nilable(OpenAI::Realtime::RealtimeResponse::Audio)) }
        attr_reader :audio

        sig do
          params(audio: OpenAI::Realtime::RealtimeResponse::Audio::OrHash).void
        end
        attr_writer :audio

        # Which conversation the response is added to, determined by the `conversation`
        # field in the `response.create` event. If `auto`, the response will be added to
        # the default conversation and the value of `conversation_id` will be an id like
        # `conv_1234`. If `none`, the response will not be added to any conversation and
        # the value of `conversation_id` will be `null`. If responses are being triggered
        # automatically by VAD the response will be added to the default conversation
        sig { returns(T.nilable(String)) }
        attr_reader :conversation_id

        sig { params(conversation_id: String).void }
        attr_writer :conversation_id

        # Maximum number of output tokens for a single assistant response, inclusive of
        # tool calls, that was used in this response.
        sig { returns(T.nilable(T.any(Integer, Symbol))) }
        attr_reader :max_output_tokens

        sig { params(max_output_tokens: T.any(Integer, Symbol)).void }
        attr_writer :max_output_tokens

        # Set of 16 key-value pairs that can be attached to an object. This can be useful
        # for storing additional information about the object in a structured format, and
        # querying for objects via API or the dashboard.
        #
        # Keys are strings with a maximum length of 64 characters. Values are strings with
        # a maximum length of 512 characters.
        sig { returns(T.nilable(T::Hash[Symbol, String])) }
        attr_accessor :metadata

        # The object type, must be `realtime.response`.
        sig do
          returns(
            T.nilable(OpenAI::Realtime::RealtimeResponse::Object::OrSymbol)
          )
        end
        attr_reader :object

        sig do
          params(
            object: OpenAI::Realtime::RealtimeResponse::Object::OrSymbol
          ).void
        end
        attr_writer :object

        # The list of output items generated by the response.
        sig do
          returns(
            T.nilable(
              T::Array[
                T.any(
                  OpenAI::Realtime::RealtimeConversationItemSystemMessage,
                  OpenAI::Realtime::RealtimeConversationItemUserMessage,
                  OpenAI::Realtime::RealtimeConversationItemAssistantMessage,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCall,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCallOutput,
                  OpenAI::Realtime::RealtimeMcpApprovalResponse,
                  OpenAI::Realtime::RealtimeMcpListTools,
                  OpenAI::Realtime::RealtimeMcpToolCall,
                  OpenAI::Realtime::RealtimeMcpApprovalRequest
                )
              ]
            )
          )
        end
        attr_reader :output

        sig do
          params(
            output:
              T::Array[
                T.any(
                  OpenAI::Realtime::RealtimeConversationItemSystemMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemUserMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemAssistantMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCall::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCallOutput::OrHash,
                  OpenAI::Realtime::RealtimeMcpApprovalResponse::OrHash,
                  OpenAI::Realtime::RealtimeMcpListTools::OrHash,
                  OpenAI::Realtime::RealtimeMcpToolCall::OrHash,
                  OpenAI::Realtime::RealtimeMcpApprovalRequest::OrHash
                )
              ]
          ).void
        end
        attr_writer :output

        # The set of modalities the model used to respond, currently the only possible
        # values are `[\"audio\"]`, `[\"text\"]`. Audio output always include a text
        # transcript. Setting the output to mode `text` will disable audio output from the
        # model.
        sig do
          returns(
            T.nilable(
              T::Array[
                OpenAI::Realtime::RealtimeResponse::OutputModality::OrSymbol
              ]
            )
          )
        end
        attr_reader :output_modalities

        sig do
          params(
            output_modalities:
              T::Array[
                OpenAI::Realtime::RealtimeResponse::OutputModality::OrSymbol
              ]
          ).void
        end
        attr_writer :output_modalities

        # The final status of the response (`completed`, `cancelled`, `failed`, or
        # `incomplete`, `in_progress`).
        sig do
          returns(
            T.nilable(OpenAI::Realtime::RealtimeResponse::Status::OrSymbol)
          )
        end
        attr_reader :status

        sig do
          params(
            status: OpenAI::Realtime::RealtimeResponse::Status::OrSymbol
          ).void
        end
        attr_writer :status

        # Additional details about the status.
        sig { returns(T.nilable(OpenAI::Realtime::RealtimeResponseStatus)) }
        attr_reader :status_details

        sig do
          params(
            status_details: OpenAI::Realtime::RealtimeResponseStatus::OrHash
          ).void
        end
        attr_writer :status_details

        # Usage statistics for the Response, this will correspond to billing. A Realtime
        # API session will maintain a conversation context and append new Items to the
        # Conversation, thus output from previous turns (text and audio tokens) will
        # become the input for later turns.
        sig { returns(T.nilable(OpenAI::Realtime::RealtimeResponseUsage)) }
        attr_reader :usage

        sig do
          params(usage: OpenAI::Realtime::RealtimeResponseUsage::OrHash).void
        end
        attr_writer :usage

        # The response resource.
        sig do
          params(
            id: String,
            audio: OpenAI::Realtime::RealtimeResponse::Audio::OrHash,
            conversation_id: String,
            max_output_tokens: T.any(Integer, Symbol),
            metadata: T.nilable(T::Hash[Symbol, String]),
            object: OpenAI::Realtime::RealtimeResponse::Object::OrSymbol,
            output:
              T::Array[
                T.any(
                  OpenAI::Realtime::RealtimeConversationItemSystemMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemUserMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemAssistantMessage::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCall::OrHash,
                  OpenAI::Realtime::RealtimeConversationItemFunctionCallOutput::OrHash,
                  OpenAI::Realtime::RealtimeMcpApprovalResponse::OrHash,
                  OpenAI::Realtime::RealtimeMcpListTools::OrHash,
                  OpenAI::Realtime::RealtimeMcpToolCall::OrHash,
                  OpenAI::Realtime::RealtimeMcpApprovalRequest::OrHash
                )
              ],
            output_modalities:
              T::Array[
                OpenAI::Realtime::RealtimeResponse::OutputModality::OrSymbol
              ],
            status: OpenAI::Realtime::RealtimeResponse::Status::OrSymbol,
            status_details: OpenAI::Realtime::RealtimeResponseStatus::OrHash,
            usage: OpenAI::Realtime::RealtimeResponseUsage::OrHash
          ).returns(T.attached_class)
        end
        def self.new(
          # The unique ID of the response, will look like `resp_1234`.
          id: nil,
          # Configuration for audio output.
          audio: nil,
          # Which conversation the response is added to, determined by the `conversation`
          # field in the `response.create` event. If `auto`, the response will be added to
          # the default conversation and the value of `conversation_id` will be an id like
          # `conv_1234`. If `none`, the response will not be added to any conversation and
          # the value of `conversation_id` will be `null`. If responses are being triggered
          # automatically by VAD the response will be added to the default conversation
          conversation_id: nil,
          # Maximum number of output tokens for a single assistant response, inclusive of
          # tool calls, that was used in this response.
          max_output_tokens: nil,
          # Set of 16 key-value pairs that can be attached to an object. This can be useful
          # for storing additional information about the object in a structured format, and
          # querying for objects via API or the dashboard.
          #
          # Keys are strings with a maximum length of 64 characters. Values are strings with
          # a maximum length of 512 characters.
          metadata: nil,
          # The object type, must be `realtime.response`.
          object: nil,
          # The list of output items generated by the response.
          output: nil,
          # The set of modalities the model used to respond, currently the only possible
          # values are `[\"audio\"]`, `[\"text\"]`. Audio output always include a text
          # transcript. Setting the output to mode `text` will disable audio output from the
          # model.
          output_modalities: nil,
          # The final status of the response (`completed`, `cancelled`, `failed`, or
          # `incomplete`, `in_progress`).
          status: nil,
          # Additional details about the status.
          status_details: nil,
          # Usage statistics for the Response, this will correspond to billing. A Realtime
          # API session will maintain a conversation context and append new Items to the
          # Conversation, thus output from previous turns (text and audio tokens) will
          # become the input for later turns.
          usage: nil
        )
        end

        sig do
          override.returns(
            {
              id: String,
              audio: OpenAI::Realtime::RealtimeResponse::Audio,
              conversation_id: String,
              max_output_tokens: T.any(Integer, Symbol),
              metadata: T.nilable(T::Hash[Symbol, String]),
              object: OpenAI::Realtime::RealtimeResponse::Object::OrSymbol,
              output:
                T::Array[
                  T.any(
                    OpenAI::Realtime::RealtimeConversationItemSystemMessage,
                    OpenAI::Realtime::RealtimeConversationItemUserMessage,
                    OpenAI::Realtime::RealtimeConversationItemAssistantMessage,
                    OpenAI::Realtime::RealtimeConversationItemFunctionCall,
                    OpenAI::Realtime::RealtimeConversationItemFunctionCallOutput,
                    OpenAI::Realtime::RealtimeMcpApprovalResponse,
                    OpenAI::Realtime::RealtimeMcpListTools,
                    OpenAI::Realtime::RealtimeMcpToolCall,
                    OpenAI::Realtime::RealtimeMcpApprovalRequest
                  )
                ],
              output_modalities:
                T::Array[
                  OpenAI::Realtime::RealtimeResponse::OutputModality::OrSymbol
                ],
              status: OpenAI::Realtime::RealtimeResponse::Status::OrSymbol,
              status_details: OpenAI::Realtime::RealtimeResponseStatus,
              usage: OpenAI::Realtime::RealtimeResponseUsage
            }
          )
        end
        def to_hash
        end

        class Audio < OpenAI::Internal::Type::BaseModel
          OrHash =
            T.type_alias do
              T.any(
                OpenAI::Realtime::RealtimeResponse::Audio,
                OpenAI::Internal::AnyHash
              )
            end

          sig do
            returns(
              T.nilable(OpenAI::Realtime::RealtimeResponse::Audio::Output)
            )
          end
          attr_reader :output

          sig do
            params(
              output: OpenAI::Realtime::RealtimeResponse::Audio::Output::OrHash
            ).void
          end
          attr_writer :output

          # Configuration for audio output.
          sig do
            params(
              output: OpenAI::Realtime::RealtimeResponse::Audio::Output::OrHash
            ).returns(T.attached_class)
          end
          def self.new(output: nil)
          end

          sig do
            override.returns(
              { output: OpenAI::Realtime::RealtimeResponse::Audio::Output }
            )
          end
          def to_hash
          end

          class Output < OpenAI::Internal::Type::BaseModel
            OrHash =
              T.type_alias do
                T.any(
                  OpenAI::Realtime::RealtimeResponse::Audio::Output,
                  OpenAI::Internal::AnyHash
                )
              end

            # The format of the output audio.
            sig do
              returns(
                T.nilable(
                  T.any(
                    OpenAI::Realtime::RealtimeAudioFormats::AudioPCM,
                    OpenAI::Realtime::RealtimeAudioFormats::AudioPCMU,
                    OpenAI::Realtime::RealtimeAudioFormats::AudioPCMA
                  )
                )
              )
            end
            attr_reader :format_

            sig do
              params(
                format_:
                  T.any(
                    OpenAI::Realtime::RealtimeAudioFormats::AudioPCM::OrHash,
                    OpenAI::Realtime::RealtimeAudioFormats::AudioPCMU::OrHash,
                    OpenAI::Realtime::RealtimeAudioFormats::AudioPCMA::OrHash
                  )
              ).void
            end
            attr_writer :format_

            # The voice the model uses to respond. Voice cannot be changed during the session
            # once the model has responded with audio at least once. Current voice options are
            # `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`,
            # and `cedar`. We recommend `marin` and `cedar` for best quality.
            sig do
              returns(
                T.nilable(
                  T.any(
                    String,
                    OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::OrSymbol
                  )
                )
              )
            end
            attr_reader :voice

            sig do
              params(
                voice:
                  T.any(
                    String,
                    OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::OrSymbol
                  )
              ).void
            end
            attr_writer :voice

            sig do
              params(
                format_:
                  T.any(
                    OpenAI::Realtime::RealtimeAudioFormats::AudioPCM::OrHash,
                    OpenAI::Realtime::RealtimeAudioFormats::AudioPCMU::OrHash,
                    OpenAI::Realtime::RealtimeAudioFormats::AudioPCMA::OrHash
                  ),
                voice:
                  T.any(
                    String,
                    OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::OrSymbol
                  )
              ).returns(T.attached_class)
            end
            def self.new(
              # The format of the output audio.
              format_: nil,
              # The voice the model uses to respond. Voice cannot be changed during the session
              # once the model has responded with audio at least once. Current voice options are
              # `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`,
              # and `cedar`. We recommend `marin` and `cedar` for best quality.
              voice: nil
            )
            end

            sig do
              override.returns(
                {
                  format_:
                    T.any(
                      OpenAI::Realtime::RealtimeAudioFormats::AudioPCM,
                      OpenAI::Realtime::RealtimeAudioFormats::AudioPCMU,
                      OpenAI::Realtime::RealtimeAudioFormats::AudioPCMA
                    ),
                  voice:
                    T.any(
                      String,
                      OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::OrSymbol
                    )
                }
              )
            end
            def to_hash
            end

            # The voice the model uses to respond. Voice cannot be changed during the session
            # once the model has responded with audio at least once. Current voice options are
            # `alloy`, `ash`, `ballad`, `coral`, `echo`, `sage`, `shimmer`, `verse`, `marin`,
            # and `cedar`. We recommend `marin` and `cedar` for best quality.
            module Voice
              extend OpenAI::Internal::Type::Union

              Variants =
                T.type_alias do
                  T.any(
                    String,
                    OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                  )
                end

              sig do
                override.returns(
                  T::Array[
                    OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::Variants
                  ]
                )
              end
              def self.variants
              end

              TaggedSymbol =
                T.type_alias do
                  T.all(
                    Symbol,
                    OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice
                  )
                end
              OrSymbol = T.type_alias { T.any(Symbol, String) }

              ALLOY =
                T.let(
                  :alloy,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
              ASH =
                T.let(
                  :ash,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
              BALLAD =
                T.let(
                  :ballad,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
              CORAL =
                T.let(
                  :coral,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
              ECHO =
                T.let(
                  :echo,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
              SAGE =
                T.let(
                  :sage,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
              SHIMMER =
                T.let(
                  :shimmer,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
              VERSE =
                T.let(
                  :verse,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
              MARIN =
                T.let(
                  :marin,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
              CEDAR =
                T.let(
                  :cedar,
                  OpenAI::Realtime::RealtimeResponse::Audio::Output::Voice::TaggedSymbol
                )
            end
          end
        end

        # Maximum number of output tokens for a single assistant response, inclusive of
        # tool calls, that was used in this response.
        module MaxOutputTokens
          extend OpenAI::Internal::Type::Union

          Variants = T.type_alias { T.any(Integer, Symbol) }

          sig do
            override.returns(
              T::Array[
                OpenAI::Realtime::RealtimeResponse::MaxOutputTokens::Variants
              ]
            )
          end
          def self.variants
          end
        end

        # The object type, must be `realtime.response`.
        module Object
          extend OpenAI::Internal::Type::Enum

          TaggedSymbol =
            T.type_alias do
              T.all(Symbol, OpenAI::Realtime::RealtimeResponse::Object)
            end
          OrSymbol = T.type_alias { T.any(Symbol, String) }

          REALTIME_RESPONSE =
            T.let(
              :"realtime.response",
              OpenAI::Realtime::RealtimeResponse::Object::TaggedSymbol
            )

          sig do
            override.returns(
              T::Array[OpenAI::Realtime::RealtimeResponse::Object::TaggedSymbol]
            )
          end
          def self.values
          end
        end

        module OutputModality
          extend OpenAI::Internal::Type::Enum

          TaggedSymbol =
            T.type_alias do
              T.all(Symbol, OpenAI::Realtime::RealtimeResponse::OutputModality)
            end
          OrSymbol = T.type_alias { T.any(Symbol, String) }

          TEXT =
            T.let(
              :text,
              OpenAI::Realtime::RealtimeResponse::OutputModality::TaggedSymbol
            )
          AUDIO =
            T.let(
              :audio,
              OpenAI::Realtime::RealtimeResponse::OutputModality::TaggedSymbol
            )

          sig do
            override.returns(
              T::Array[
                OpenAI::Realtime::RealtimeResponse::OutputModality::TaggedSymbol
              ]
            )
          end
          def self.values
          end
        end

        # The final status of the response (`completed`, `cancelled`, `failed`, or
        # `incomplete`, `in_progress`).
        module Status
          extend OpenAI::Internal::Type::Enum

          TaggedSymbol =
            T.type_alias do
              T.all(Symbol, OpenAI::Realtime::RealtimeResponse::Status)
            end
          OrSymbol = T.type_alias { T.any(Symbol, String) }

          COMPLETED =
            T.let(
              :completed,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )
          CANCELLED =
            T.let(
              :cancelled,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )
          FAILED =
            T.let(
              :failed,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )
          INCOMPLETE =
            T.let(
              :incomplete,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )
          IN_PROGRESS =
            T.let(
              :in_progress,
              OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol
            )

          sig do
            override.returns(
              T::Array[OpenAI::Realtime::RealtimeResponse::Status::TaggedSymbol]
            )
          end
          def self.values
          end
        end
      end
    end
  end
end
