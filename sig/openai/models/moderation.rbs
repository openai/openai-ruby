module OpenAI
  module Models
    type moderation =
      {
        categories: OpenAI::Models::Moderation::Categories,
        category_applied_input_types: OpenAI::Models::Moderation::CategoryAppliedInputTypes,
        category_scores: OpenAI::Models::Moderation::CategoryScores,
        flagged: bool
      }

    class Moderation < OpenAI::Internal::Type::BaseModel
      attr_accessor categories: OpenAI::Models::Moderation::Categories

      attr_accessor category_applied_input_types: OpenAI::Models::Moderation::CategoryAppliedInputTypes

      attr_accessor category_scores: OpenAI::Models::Moderation::CategoryScores

      attr_accessor flagged: bool

      def initialize: (
        categories: OpenAI::Models::Moderation::Categories,
        category_applied_input_types: OpenAI::Models::Moderation::CategoryAppliedInputTypes,
        category_scores: OpenAI::Models::Moderation::CategoryScores,
        flagged: bool
      ) -> void

      def to_hash: -> OpenAI::Models::moderation

      type categories =
        {
          harassment: bool,
          harassment_threatening: bool,
          hate: bool,
          hate_threatening: bool,
          illicit: bool?,
          illicit_violent: bool?,
          self_harm: bool,
          self_harm_instructions: bool,
          self_harm_intent: bool,
          sexual: bool,
          sexual_minors: bool,
          violence: bool,
          violence_graphic: bool
        }

      class Categories < OpenAI::Internal::Type::BaseModel
        attr_accessor harassment: bool

        attr_accessor harassment_threatening: bool

        attr_accessor hate: bool

        attr_accessor hate_threatening: bool

        attr_accessor illicit: bool?

        attr_accessor illicit_violent: bool?

        attr_accessor self_harm: bool

        attr_accessor self_harm_instructions: bool

        attr_accessor self_harm_intent: bool

        attr_accessor sexual: bool

        attr_accessor sexual_minors: bool

        attr_accessor violence: bool

        attr_accessor violence_graphic: bool

        def initialize: (
          harassment: bool,
          harassment_threatening: bool,
          hate: bool,
          hate_threatening: bool,
          illicit: bool?,
          illicit_violent: bool?,
          self_harm: bool,
          self_harm_instructions: bool,
          self_harm_intent: bool,
          sexual: bool,
          sexual_minors: bool,
          violence: bool,
          violence_graphic: bool
        ) -> void

        def to_hash: -> OpenAI::Models::Moderation::categories
      end

      type category_applied_input_types =
        {
          harassment: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::harassment],
          harassment_threatening: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::harassment_threatening],
          hate: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::hate],
          hate_threatening: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::hate_threatening],
          illicit: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::illicit],
          illicit_violent: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::illicit_violent],
          self_harm: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm],
          self_harm_instructions: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm_instruction],
          self_harm_intent: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm_intent],
          sexual: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::sexual],
          sexual_minors: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::sexual_minor],
          violence: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::violence],
          violence_graphic: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::violence_graphic]
        }

      class CategoryAppliedInputTypes < OpenAI::Internal::Type::BaseModel
        attr_accessor harassment: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::harassment]

        attr_accessor harassment_threatening: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::harassment_threatening]

        attr_accessor hate: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::hate]

        attr_accessor hate_threatening: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::hate_threatening]

        attr_accessor illicit: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::illicit]

        attr_accessor illicit_violent: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::illicit_violent]

        attr_accessor self_harm: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm]

        attr_accessor self_harm_instructions: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm_instruction]

        attr_accessor self_harm_intent: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm_intent]

        attr_accessor sexual: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::sexual]

        attr_accessor sexual_minors: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::sexual_minor]

        attr_accessor violence: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::violence]

        attr_accessor violence_graphic: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::violence_graphic]

        def initialize: (
          harassment: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::harassment],
          harassment_threatening: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::harassment_threatening],
          hate: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::hate],
          hate_threatening: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::hate_threatening],
          illicit: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::illicit],
          illicit_violent: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::illicit_violent],
          self_harm: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm],
          self_harm_instructions: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm_instruction],
          self_harm_intent: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm_intent],
          sexual: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::sexual],
          sexual_minors: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::sexual_minor],
          violence: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::violence],
          violence_graphic: ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::violence_graphic]
        ) -> void

        def to_hash: -> OpenAI::Models::Moderation::category_applied_input_types

        type harassment = :text

        module Harassment
          extend OpenAI::Internal::Type::Enum

          TEXT: :text

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::harassment]
        end

        type harassment_threatening = :text

        module HarassmentThreatening
          extend OpenAI::Internal::Type::Enum

          TEXT: :text

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::harassment_threatening]
        end

        type hate = :text

        module Hate
          extend OpenAI::Internal::Type::Enum

          TEXT: :text

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::hate]
        end

        type hate_threatening = :text

        module HateThreatening
          extend OpenAI::Internal::Type::Enum

          TEXT: :text

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::hate_threatening]
        end

        type illicit = :text

        module Illicit
          extend OpenAI::Internal::Type::Enum

          TEXT: :text

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::illicit]
        end

        type illicit_violent = :text

        module IllicitViolent
          extend OpenAI::Internal::Type::Enum

          TEXT: :text

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::illicit_violent]
        end

        type self_harm = :text | :image

        module SelfHarm
          extend OpenAI::Internal::Type::Enum

          TEXT: :text
          IMAGE: :image

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm]
        end

        type self_harm_instruction = :text | :image

        module SelfHarmInstruction
          extend OpenAI::Internal::Type::Enum

          TEXT: :text
          IMAGE: :image

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm_instruction]
        end

        type self_harm_intent = :text | :image

        module SelfHarmIntent
          extend OpenAI::Internal::Type::Enum

          TEXT: :text
          IMAGE: :image

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::self_harm_intent]
        end

        type sexual = :text | :image

        module Sexual
          extend OpenAI::Internal::Type::Enum

          TEXT: :text
          IMAGE: :image

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::sexual]
        end

        type sexual_minor = :text

        module SexualMinor
          extend OpenAI::Internal::Type::Enum

          TEXT: :text

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::sexual_minor]
        end

        type violence = :text | :image

        module Violence
          extend OpenAI::Internal::Type::Enum

          TEXT: :text
          IMAGE: :image

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::violence]
        end

        type violence_graphic = :text | :image

        module ViolenceGraphic
          extend OpenAI::Internal::Type::Enum

          TEXT: :text
          IMAGE: :image

          def self?.values: -> ::Array[OpenAI::Models::Moderation::CategoryAppliedInputTypes::violence_graphic]
        end
      end

      type category_scores =
        {
          harassment: Float,
          harassment_threatening: Float,
          hate: Float,
          hate_threatening: Float,
          illicit: Float,
          illicit_violent: Float,
          self_harm: Float,
          self_harm_instructions: Float,
          self_harm_intent: Float,
          sexual: Float,
          sexual_minors: Float,
          violence: Float,
          violence_graphic: Float
        }

      class CategoryScores < OpenAI::Internal::Type::BaseModel
        attr_accessor harassment: Float

        attr_accessor harassment_threatening: Float

        attr_accessor hate: Float

        attr_accessor hate_threatening: Float

        attr_accessor illicit: Float

        attr_accessor illicit_violent: Float

        attr_accessor self_harm: Float

        attr_accessor self_harm_instructions: Float

        attr_accessor self_harm_intent: Float

        attr_accessor sexual: Float

        attr_accessor sexual_minors: Float

        attr_accessor violence: Float

        attr_accessor violence_graphic: Float

        def initialize: (
          harassment: Float,
          harassment_threatening: Float,
          hate: Float,
          hate_threatening: Float,
          illicit: Float,
          illicit_violent: Float,
          self_harm: Float,
          self_harm_instructions: Float,
          self_harm_intent: Float,
          sexual: Float,
          sexual_minors: Float,
          violence: Float,
          violence_graphic: Float
        ) -> void

        def to_hash: -> OpenAI::Models::Moderation::category_scores
      end
    end
  end
end
