module OpenAI
  module Models
    module Chat
      type completion_create_params =
        {
          messages: ::Array[OpenAI::Models::Chat::chat_completion_message_param],
          model: OpenAI::Models::Chat::CompletionCreateParams::model,
          audio: OpenAI::Chat::ChatCompletionAudioParam?,
          frequency_penalty: Float?,
          function_call: OpenAI::Models::Chat::CompletionCreateParams::function_call,
          functions: ::Array[OpenAI::Chat::CompletionCreateParams::Function],
          logit_bias: ::Hash[Symbol, Integer]?,
          logprobs: bool?,
          max_completion_tokens: Integer?,
          max_tokens: Integer?,
          metadata: OpenAI::Models::metadata?,
          modalities: ::Array[OpenAI::Models::Chat::CompletionCreateParams::modality]?,
          n: Integer?,
          parallel_tool_calls: bool,
          prediction: OpenAI::Chat::ChatCompletionPredictionContent?,
          presence_penalty: Float?,
          prompt_cache_key: String,
          reasoning_effort: OpenAI::Models::reasoning_effort?,
          response_format: OpenAI::Models::Chat::CompletionCreateParams::response_format,
          safety_identifier: String,
          seed: Integer?,
          service_tier: OpenAI::Models::Chat::CompletionCreateParams::service_tier?,
          stop: OpenAI::Models::Chat::CompletionCreateParams::stop?,
          store: bool?,
          stream_options: OpenAI::Chat::ChatCompletionStreamOptions?,
          temperature: Float?,
          tool_choice: OpenAI::Models::Chat::chat_completion_tool_choice_option,
          tools: ::Array[OpenAI::Models::Chat::chat_completion_tool],
          top_logprobs: Integer?,
          top_p: Float?,
          user: String,
          verbosity: OpenAI::Models::Chat::CompletionCreateParams::verbosity?,
          web_search_options: OpenAI::Chat::CompletionCreateParams::WebSearchOptions
        }
        & OpenAI::Internal::Type::request_parameters

      class CompletionCreateParams < OpenAI::Internal::Type::BaseModel
        extend OpenAI::Internal::Type::RequestParameters::Converter
        include OpenAI::Internal::Type::RequestParameters

        attr_accessor messages: ::Array[OpenAI::Models::Chat::chat_completion_message_param]

        attr_accessor model: OpenAI::Models::Chat::CompletionCreateParams::model

        attr_accessor audio: OpenAI::Chat::ChatCompletionAudioParam?

        attr_accessor frequency_penalty: Float?

        attr_reader function_call: OpenAI::Models::Chat::CompletionCreateParams::function_call?

        def function_call=: (
          OpenAI::Models::Chat::CompletionCreateParams::function_call
        ) -> OpenAI::Models::Chat::CompletionCreateParams::function_call

        attr_reader functions: ::Array[OpenAI::Chat::CompletionCreateParams::Function]?

        def functions=: (
          ::Array[OpenAI::Chat::CompletionCreateParams::Function]
        ) -> ::Array[OpenAI::Chat::CompletionCreateParams::Function]

        attr_accessor logit_bias: ::Hash[Symbol, Integer]?

        attr_accessor logprobs: bool?

        attr_accessor max_completion_tokens: Integer?

        attr_accessor max_tokens: Integer?

        attr_accessor metadata: OpenAI::Models::metadata?

        attr_accessor modalities: ::Array[OpenAI::Models::Chat::CompletionCreateParams::modality]?

        attr_accessor n: Integer?

        attr_reader parallel_tool_calls: bool?

        def parallel_tool_calls=: (bool) -> bool

        attr_accessor prediction: OpenAI::Chat::ChatCompletionPredictionContent?

        attr_accessor presence_penalty: Float?

        attr_reader prompt_cache_key: String?

        def prompt_cache_key=: (String) -> String

        attr_accessor reasoning_effort: OpenAI::Models::reasoning_effort?

        attr_reader response_format: OpenAI::Models::Chat::CompletionCreateParams::response_format?

        def response_format=: (
          OpenAI::Models::Chat::CompletionCreateParams::response_format
        ) -> OpenAI::Models::Chat::CompletionCreateParams::response_format

        attr_reader safety_identifier: String?

        def safety_identifier=: (String) -> String

        attr_accessor seed: Integer?

        attr_accessor service_tier: OpenAI::Models::Chat::CompletionCreateParams::service_tier?

        attr_accessor stop: OpenAI::Models::Chat::CompletionCreateParams::stop?

        attr_accessor store: bool?

        attr_accessor stream_options: OpenAI::Chat::ChatCompletionStreamOptions?

        attr_accessor temperature: Float?

        attr_reader tool_choice: OpenAI::Models::Chat::chat_completion_tool_choice_option?

        def tool_choice=: (
          OpenAI::Models::Chat::chat_completion_tool_choice_option
        ) -> OpenAI::Models::Chat::chat_completion_tool_choice_option

        attr_reader tools: ::Array[OpenAI::Models::Chat::chat_completion_tool]?

        def tools=: (
          ::Array[OpenAI::Models::Chat::chat_completion_tool]
        ) -> ::Array[OpenAI::Models::Chat::chat_completion_tool]

        attr_accessor top_logprobs: Integer?

        attr_accessor top_p: Float?

        attr_reader user: String?

        def user=: (String) -> String

        attr_accessor verbosity: OpenAI::Models::Chat::CompletionCreateParams::verbosity?

        attr_reader web_search_options: OpenAI::Chat::CompletionCreateParams::WebSearchOptions?

        def web_search_options=: (
          OpenAI::Chat::CompletionCreateParams::WebSearchOptions
        ) -> OpenAI::Chat::CompletionCreateParams::WebSearchOptions

        def initialize: (
          messages: ::Array[OpenAI::Models::Chat::chat_completion_message_param],
          model: OpenAI::Models::Chat::CompletionCreateParams::model,
          ?audio: OpenAI::Chat::ChatCompletionAudioParam?,
          ?frequency_penalty: Float?,
          ?function_call: OpenAI::Models::Chat::CompletionCreateParams::function_call,
          ?functions: ::Array[OpenAI::Chat::CompletionCreateParams::Function],
          ?logit_bias: ::Hash[Symbol, Integer]?,
          ?logprobs: bool?,
          ?max_completion_tokens: Integer?,
          ?max_tokens: Integer?,
          ?metadata: OpenAI::Models::metadata?,
          ?modalities: ::Array[OpenAI::Models::Chat::CompletionCreateParams::modality]?,
          ?n: Integer?,
          ?parallel_tool_calls: bool,
          ?prediction: OpenAI::Chat::ChatCompletionPredictionContent?,
          ?presence_penalty: Float?,
          ?prompt_cache_key: String,
          ?reasoning_effort: OpenAI::Models::reasoning_effort?,
          ?response_format: OpenAI::Models::Chat::CompletionCreateParams::response_format,
          ?safety_identifier: String,
          ?seed: Integer?,
          ?service_tier: OpenAI::Models::Chat::CompletionCreateParams::service_tier?,
          ?stop: OpenAI::Models::Chat::CompletionCreateParams::stop?,
          ?store: bool?,
          ?stream_options: OpenAI::Chat::ChatCompletionStreamOptions?,
          ?temperature: Float?,
          ?tool_choice: OpenAI::Models::Chat::chat_completion_tool_choice_option,
          ?tools: ::Array[OpenAI::Models::Chat::chat_completion_tool],
          ?top_logprobs: Integer?,
          ?top_p: Float?,
          ?user: String,
          ?verbosity: OpenAI::Models::Chat::CompletionCreateParams::verbosity?,
          ?web_search_options: OpenAI::Chat::CompletionCreateParams::WebSearchOptions,
          ?request_options: OpenAI::request_opts
        ) -> void

        def to_hash: -> {
          messages: ::Array[OpenAI::Models::Chat::chat_completion_message_param],
          model: OpenAI::Models::Chat::CompletionCreateParams::model,
          audio: OpenAI::Chat::ChatCompletionAudioParam?,
          frequency_penalty: Float?,
          function_call: OpenAI::Models::Chat::CompletionCreateParams::function_call,
          functions: ::Array[OpenAI::Chat::CompletionCreateParams::Function],
          logit_bias: ::Hash[Symbol, Integer]?,
          logprobs: bool?,
          max_completion_tokens: Integer?,
          max_tokens: Integer?,
          metadata: OpenAI::Models::metadata?,
          modalities: ::Array[OpenAI::Models::Chat::CompletionCreateParams::modality]?,
          n: Integer?,
          parallel_tool_calls: bool,
          prediction: OpenAI::Chat::ChatCompletionPredictionContent?,
          presence_penalty: Float?,
          prompt_cache_key: String,
          reasoning_effort: OpenAI::Models::reasoning_effort?,
          response_format: OpenAI::Models::Chat::CompletionCreateParams::response_format,
          safety_identifier: String,
          seed: Integer?,
          service_tier: OpenAI::Models::Chat::CompletionCreateParams::service_tier?,
          stop: OpenAI::Models::Chat::CompletionCreateParams::stop?,
          store: bool?,
          stream_options: OpenAI::Chat::ChatCompletionStreamOptions?,
          temperature: Float?,
          tool_choice: OpenAI::Models::Chat::chat_completion_tool_choice_option,
          tools: ::Array[OpenAI::Models::Chat::chat_completion_tool],
          top_logprobs: Integer?,
          top_p: Float?,
          user: String,
          verbosity: OpenAI::Models::Chat::CompletionCreateParams::verbosity?,
          web_search_options: OpenAI::Chat::CompletionCreateParams::WebSearchOptions,
          request_options: OpenAI::RequestOptions
        }

        type model = String | OpenAI::Models::chat_model

        module Model
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Chat::CompletionCreateParams::model]
        end

        type function_call =
          OpenAI::Models::Chat::CompletionCreateParams::FunctionCall::function_call_mode
          | OpenAI::Chat::ChatCompletionFunctionCallOption

        module FunctionCall
          extend OpenAI::Internal::Type::Union

          type function_call_mode = :none | :auto

          module FunctionCallMode
            extend OpenAI::Internal::Type::Enum

            NONE: :none
            AUTO: :auto

            def self?.values: -> ::Array[OpenAI::Models::Chat::CompletionCreateParams::FunctionCall::function_call_mode]
          end

          def self?.variants: -> ::Array[OpenAI::Models::Chat::CompletionCreateParams::function_call]
        end

        type function =
          {
            name: String,
            description: String,
            parameters: OpenAI::Models::function_parameters
          }

        class Function < OpenAI::Internal::Type::BaseModel
          attr_accessor name: String

          attr_reader description: String?

          def description=: (String) -> String

          attr_reader parameters: OpenAI::Models::function_parameters?

          def parameters=: (
            OpenAI::Models::function_parameters
          ) -> OpenAI::Models::function_parameters

          def initialize: (
            name: String,
            ?description: String,
            ?parameters: OpenAI::Models::function_parameters
          ) -> void

          def to_hash: -> {
            name: String,
            description: String,
            parameters: OpenAI::Models::function_parameters
          }
        end

        type modality = :text | :audio

        module Modality
          extend OpenAI::Internal::Type::Enum

          TEXT: :text
          AUDIO: :audio

          def self?.values: -> ::Array[OpenAI::Models::Chat::CompletionCreateParams::modality]
        end

        type response_format =
          OpenAI::ResponseFormatText
          | OpenAI::ResponseFormatJSONSchema
          | OpenAI::ResponseFormatJSONObject

        module ResponseFormat
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Chat::CompletionCreateParams::response_format]
        end

        type service_tier = :auto | :default | :flex | :scale | :priority

        module ServiceTier
          extend OpenAI::Internal::Type::Enum

          AUTO: :auto
          DEFAULT: :default
          FLEX: :flex
          SCALE: :scale
          PRIORITY: :priority

          def self?.values: -> ::Array[OpenAI::Models::Chat::CompletionCreateParams::service_tier]
        end

        type stop = (String | ::Array[String])?

        module Stop
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Chat::CompletionCreateParams::stop]

          StringArray: OpenAI::Internal::Type::Converter
        end

        type verbosity = :low | :medium | :high

        module Verbosity
          extend OpenAI::Internal::Type::Enum

          LOW: :low
          MEDIUM: :medium
          HIGH: :high

          def self?.values: -> ::Array[OpenAI::Models::Chat::CompletionCreateParams::verbosity]
        end

        type web_search_options =
          {
            search_context_size: OpenAI::Models::Chat::CompletionCreateParams::WebSearchOptions::search_context_size,
            user_location: OpenAI::Chat::CompletionCreateParams::WebSearchOptions::UserLocation?
          }

        class WebSearchOptions < OpenAI::Internal::Type::BaseModel
          attr_reader search_context_size: OpenAI::Models::Chat::CompletionCreateParams::WebSearchOptions::search_context_size?

          def search_context_size=: (
            OpenAI::Models::Chat::CompletionCreateParams::WebSearchOptions::search_context_size
          ) -> OpenAI::Models::Chat::CompletionCreateParams::WebSearchOptions::search_context_size

          attr_accessor user_location: OpenAI::Chat::CompletionCreateParams::WebSearchOptions::UserLocation?

          def initialize: (
            ?search_context_size: OpenAI::Models::Chat::CompletionCreateParams::WebSearchOptions::search_context_size,
            ?user_location: OpenAI::Chat::CompletionCreateParams::WebSearchOptions::UserLocation?
          ) -> void

          def to_hash: -> {
            search_context_size: OpenAI::Models::Chat::CompletionCreateParams::WebSearchOptions::search_context_size,
            user_location: OpenAI::Chat::CompletionCreateParams::WebSearchOptions::UserLocation?
          }

          type search_context_size = :low | :medium | :high

          module SearchContextSize
            extend OpenAI::Internal::Type::Enum

            LOW: :low
            MEDIUM: :medium
            HIGH: :high

            def self?.values: -> ::Array[OpenAI::Models::Chat::CompletionCreateParams::WebSearchOptions::search_context_size]
          end

          type user_location =
            {
              approximate: OpenAI::Chat::CompletionCreateParams::WebSearchOptions::UserLocation::Approximate,
              type: :approximate
            }

          class UserLocation < OpenAI::Internal::Type::BaseModel
            attr_accessor approximate: OpenAI::Chat::CompletionCreateParams::WebSearchOptions::UserLocation::Approximate

            attr_accessor type: :approximate

            def initialize: (
              approximate: OpenAI::Chat::CompletionCreateParams::WebSearchOptions::UserLocation::Approximate,
              ?type: :approximate
            ) -> void

            def to_hash: -> {
              approximate: OpenAI::Chat::CompletionCreateParams::WebSearchOptions::UserLocation::Approximate,
              type: :approximate
            }

            type approximate =
              {
                city: String,
                country: String,
                region: String,
                timezone: String
              }

            class Approximate < OpenAI::Internal::Type::BaseModel
              attr_reader city: String?

              def city=: (String) -> String

              attr_reader country: String?

              def country=: (String) -> String

              attr_reader region: String?

              def region=: (String) -> String

              attr_reader timezone: String?

              def timezone=: (String) -> String

              def initialize: (
                ?city: String,
                ?country: String,
                ?region: String,
                ?timezone: String
              ) -> void

              def to_hash: -> {
                city: String,
                country: String,
                region: String,
                timezone: String
              }
            end
          end
        end
      end
    end
  end
end
