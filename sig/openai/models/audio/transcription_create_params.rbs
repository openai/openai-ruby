module OpenAI
  module Models
    module Audio
      type transcription_create_params =
        {
          file: OpenAI::Internal::file_input,
          model: OpenAI::Models::Audio::TranscriptionCreateParams::model,
          chunking_strategy: OpenAI::Models::Audio::TranscriptionCreateParams::chunking_strategy?,
          include: ::Array[OpenAI::Models::Audio::transcription_include],
          known_speaker_names: ::Array[String],
          known_speaker_references: ::Array[String],
          language: String,
          prompt: String,
          response_format: OpenAI::Models::audio_response_format,
          temperature: Float,
          timestamp_granularities: ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::timestamp_granularity]
        }
        & OpenAI::Internal::Type::request_parameters

      class TranscriptionCreateParams < OpenAI::Internal::Type::BaseModel
        extend OpenAI::Internal::Type::RequestParameters::Converter
        include OpenAI::Internal::Type::RequestParameters

        attr_accessor file: OpenAI::Internal::file_input

        attr_accessor model: OpenAI::Models::Audio::TranscriptionCreateParams::model

        attr_accessor chunking_strategy: OpenAI::Models::Audio::TranscriptionCreateParams::chunking_strategy?

        attr_reader include: ::Array[OpenAI::Models::Audio::transcription_include]?

        def include=: (
          ::Array[OpenAI::Models::Audio::transcription_include]
        ) -> ::Array[OpenAI::Models::Audio::transcription_include]

        attr_reader known_speaker_names: ::Array[String]?

        def known_speaker_names=: (::Array[String]) -> ::Array[String]

        attr_reader known_speaker_references: ::Array[String]?

        def known_speaker_references=: (::Array[String]) -> ::Array[String]

        attr_reader language: String?

        def language=: (String) -> String

        attr_reader prompt: String?

        def prompt=: (String) -> String

        attr_reader response_format: OpenAI::Models::audio_response_format?

        def response_format=: (
          OpenAI::Models::audio_response_format
        ) -> OpenAI::Models::audio_response_format

        attr_reader temperature: Float?

        def temperature=: (Float) -> Float

        attr_reader timestamp_granularities: ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::timestamp_granularity]?

        def timestamp_granularities=: (
          ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::timestamp_granularity]
        ) -> ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::timestamp_granularity]

        def initialize: (
          file: OpenAI::Internal::file_input,
          model: OpenAI::Models::Audio::TranscriptionCreateParams::model,
          ?chunking_strategy: OpenAI::Models::Audio::TranscriptionCreateParams::chunking_strategy?,
          ?include: ::Array[OpenAI::Models::Audio::transcription_include],
          ?known_speaker_names: ::Array[String],
          ?known_speaker_references: ::Array[String],
          ?language: String,
          ?prompt: String,
          ?response_format: OpenAI::Models::audio_response_format,
          ?temperature: Float,
          ?timestamp_granularities: ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::timestamp_granularity],
          ?request_options: OpenAI::request_opts
        ) -> void

        def to_hash: -> {
          file: OpenAI::Internal::file_input,
          model: OpenAI::Models::Audio::TranscriptionCreateParams::model,
          chunking_strategy: OpenAI::Models::Audio::TranscriptionCreateParams::chunking_strategy?,
          include: ::Array[OpenAI::Models::Audio::transcription_include],
          known_speaker_names: ::Array[String],
          known_speaker_references: ::Array[String],
          language: String,
          prompt: String,
          response_format: OpenAI::Models::audio_response_format,
          temperature: Float,
          timestamp_granularities: ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::timestamp_granularity],
          request_options: OpenAI::RequestOptions
        }

        type model = String | OpenAI::Models::audio_model

        module Model
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::model]
        end

        type chunking_strategy =
          :auto
          | OpenAI::Audio::TranscriptionCreateParams::ChunkingStrategy::VadConfig

        module ChunkingStrategy
          extend OpenAI::Internal::Type::Union

          type vad_config =
            {
              type: OpenAI::Models::Audio::TranscriptionCreateParams::ChunkingStrategy::VadConfig::type_,
              prefix_padding_ms: Integer,
              silence_duration_ms: Integer,
              threshold: Float
            }

          class VadConfig < OpenAI::Internal::Type::BaseModel
            attr_accessor type: OpenAI::Models::Audio::TranscriptionCreateParams::ChunkingStrategy::VadConfig::type_

            attr_reader prefix_padding_ms: Integer?

            def prefix_padding_ms=: (Integer) -> Integer

            attr_reader silence_duration_ms: Integer?

            def silence_duration_ms=: (Integer) -> Integer

            attr_reader threshold: Float?

            def threshold=: (Float) -> Float

            def initialize: (
              type: OpenAI::Models::Audio::TranscriptionCreateParams::ChunkingStrategy::VadConfig::type_,
              ?prefix_padding_ms: Integer,
              ?silence_duration_ms: Integer,
              ?threshold: Float
            ) -> void

            def to_hash: -> {
              type: OpenAI::Models::Audio::TranscriptionCreateParams::ChunkingStrategy::VadConfig::type_,
              prefix_padding_ms: Integer,
              silence_duration_ms: Integer,
              threshold: Float
            }

            type type_ = :server_vad

            module Type
              extend OpenAI::Internal::Type::Enum

              SERVER_VAD: :server_vad

              def self?.values: -> ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::ChunkingStrategy::VadConfig::type_]
            end
          end

          def self?.variants: -> ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::chunking_strategy]
        end

        type timestamp_granularity = :word | :segment

        module TimestampGranularity
          extend OpenAI::Internal::Type::Enum

          WORD: :word
          SEGMENT: :segment

          def self?.values: -> ::Array[OpenAI::Models::Audio::TranscriptionCreateParams::timestamp_granularity]
        end
      end
    end
  end
end
