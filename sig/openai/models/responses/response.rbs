module OpenAI
  module Models
    module Responses
      type response =
        {
          id: String,
          created_at: Float,
          error: OpenAI::Responses::ResponseError?,
          incomplete_details: OpenAI::Responses::Response::IncompleteDetails?,
          instructions: String?,
          metadata: OpenAI::Models::metadata?,
          model: OpenAI::Models::responses_model,
          object: :response,
          output: ::Array[OpenAI::Models::Responses::response_output_item],
          parallel_tool_calls: bool,
          temperature: Float?,
          tool_choice: OpenAI::Models::Responses::Response::tool_choice,
          tools: ::Array[OpenAI::Models::Responses::tool],
          top_p: Float?,
          background: bool?,
          max_output_tokens: Integer?,
          previous_response_id: String?,
          reasoning: OpenAI::Reasoning?,
          service_tier: OpenAI::Models::Responses::Response::service_tier?,
          status: OpenAI::Models::Responses::response_status,
          text: OpenAI::Responses::ResponseTextConfig,
          truncation: OpenAI::Models::Responses::Response::truncation?,
          usage: OpenAI::Responses::ResponseUsage,
          user: String
        }

      class Response < OpenAI::Internal::Type::BaseModel
        attr_accessor id: String

        attr_accessor created_at: Float

        attr_accessor error: OpenAI::Responses::ResponseError?

        attr_accessor incomplete_details: OpenAI::Responses::Response::IncompleteDetails?

        attr_accessor instructions: String?

        attr_accessor metadata: OpenAI::Models::metadata?

        attr_accessor model: OpenAI::Models::responses_model

        attr_accessor object: :response

        attr_accessor output: ::Array[OpenAI::Models::Responses::response_output_item]

        attr_accessor parallel_tool_calls: bool

        attr_accessor temperature: Float?

        attr_accessor tool_choice: OpenAI::Models::Responses::Response::tool_choice

        attr_accessor tools: ::Array[OpenAI::Models::Responses::tool]

        attr_accessor top_p: Float?

        attr_accessor background: bool?

        attr_accessor max_output_tokens: Integer?

        attr_accessor previous_response_id: String?

        attr_accessor reasoning: OpenAI::Reasoning?

        attr_accessor service_tier: OpenAI::Models::Responses::Response::service_tier?

        attr_reader status: OpenAI::Models::Responses::response_status?

        def status=: (
          OpenAI::Models::Responses::response_status
        ) -> OpenAI::Models::Responses::response_status

        attr_reader text: OpenAI::Responses::ResponseTextConfig?

        def text=: (
          OpenAI::Responses::ResponseTextConfig
        ) -> OpenAI::Responses::ResponseTextConfig

        attr_accessor truncation: OpenAI::Models::Responses::Response::truncation?

        attr_reader usage: OpenAI::Responses::ResponseUsage?

        def usage=: (
          OpenAI::Responses::ResponseUsage
        ) -> OpenAI::Responses::ResponseUsage

        attr_reader user: String?

        def user=: (String) -> String

        def initialize: (
          id: String,
          created_at: Float,
          error: OpenAI::Responses::ResponseError?,
          incomplete_details: OpenAI::Responses::Response::IncompleteDetails?,
          instructions: String?,
          metadata: OpenAI::Models::metadata?,
          model: OpenAI::Models::responses_model,
          output: ::Array[OpenAI::Models::Responses::response_output_item],
          parallel_tool_calls: bool,
          temperature: Float?,
          tool_choice: OpenAI::Models::Responses::Response::tool_choice,
          tools: ::Array[OpenAI::Models::Responses::tool],
          top_p: Float?,
          ?background: bool?,
          ?max_output_tokens: Integer?,
          ?previous_response_id: String?,
          ?reasoning: OpenAI::Reasoning?,
          ?service_tier: OpenAI::Models::Responses::Response::service_tier?,
          ?status: OpenAI::Models::Responses::response_status,
          ?text: OpenAI::Responses::ResponseTextConfig,
          ?truncation: OpenAI::Models::Responses::Response::truncation?,
          ?usage: OpenAI::Responses::ResponseUsage,
          ?user: String,
          ?object: :response
        ) -> void

        def to_hash: -> {
          id: String,
          created_at: Float,
          error: OpenAI::Responses::ResponseError?,
          incomplete_details: OpenAI::Responses::Response::IncompleteDetails?,
          instructions: String?,
          metadata: OpenAI::Models::metadata?,
          model: OpenAI::Models::responses_model,
          object: :response,
          output: ::Array[OpenAI::Models::Responses::response_output_item],
          parallel_tool_calls: bool,
          temperature: Float?,
          tool_choice: OpenAI::Models::Responses::Response::tool_choice,
          tools: ::Array[OpenAI::Models::Responses::tool],
          top_p: Float?,
          background: bool?,
          max_output_tokens: Integer?,
          previous_response_id: String?,
          reasoning: OpenAI::Reasoning?,
          service_tier: OpenAI::Models::Responses::Response::service_tier?,
          status: OpenAI::Models::Responses::response_status,
          text: OpenAI::Responses::ResponseTextConfig,
          truncation: OpenAI::Models::Responses::Response::truncation?,
          usage: OpenAI::Responses::ResponseUsage,
          user: String
        }

        type incomplete_details =
          {
            reason: OpenAI::Models::Responses::Response::IncompleteDetails::reason
          }

        class IncompleteDetails < OpenAI::Internal::Type::BaseModel
          attr_reader reason: OpenAI::Models::Responses::Response::IncompleteDetails::reason?

          def reason=: (
            OpenAI::Models::Responses::Response::IncompleteDetails::reason
          ) -> OpenAI::Models::Responses::Response::IncompleteDetails::reason

          def initialize: (
            ?reason: OpenAI::Models::Responses::Response::IncompleteDetails::reason
          ) -> void

          def to_hash: -> {
            reason: OpenAI::Models::Responses::Response::IncompleteDetails::reason
          }

          type reason = :max_output_tokens | :content_filter

          module Reason
            extend OpenAI::Internal::Type::Enum

            MAX_OUTPUT_TOKENS: :max_output_tokens
            CONTENT_FILTER: :content_filter

            def self?.values: -> ::Array[OpenAI::Models::Responses::Response::IncompleteDetails::reason]
          end
        end

        type tool_choice =
          OpenAI::Models::Responses::tool_choice_options
          | OpenAI::Responses::ToolChoiceTypes
          | OpenAI::Responses::ToolChoiceFunction

        module ToolChoice
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Responses::Response::tool_choice]
        end

        type service_tier = :auto | :default | :flex

        module ServiceTier
          extend OpenAI::Internal::Type::Enum

          AUTO: :auto
          DEFAULT: :default
          FLEX: :flex

          def self?.values: -> ::Array[OpenAI::Models::Responses::Response::service_tier]
        end

        type truncation = :auto | :disabled

        module Truncation
          extend OpenAI::Internal::Type::Enum

          AUTO: :auto
          DISABLED: :disabled

          def self?.values: -> ::Array[OpenAI::Models::Responses::Response::truncation]
        end
      end
    end
  end
end
