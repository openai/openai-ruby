module OpenAI
  module Models
    module Realtime
      type realtime_session =
        {
          id: String,
          expires_at: Integer,
          include: ::Array[OpenAI::Models::Realtime::RealtimeSession::include_]?,
          input_audio_format: OpenAI::Models::Realtime::RealtimeSession::input_audio_format,
          input_audio_noise_reduction: OpenAI::Realtime::RealtimeSession::InputAudioNoiseReduction,
          input_audio_transcription: OpenAI::Realtime::AudioTranscription?,
          instructions: String,
          max_response_output_tokens: OpenAI::Models::Realtime::RealtimeSession::max_response_output_tokens,
          modalities: ::Array[OpenAI::Models::Realtime::RealtimeSession::modality],
          model: OpenAI::Models::Realtime::RealtimeSession::model,
          object: OpenAI::Models::Realtime::RealtimeSession::object,
          output_audio_format: OpenAI::Models::Realtime::RealtimeSession::output_audio_format,
          prompt: OpenAI::Responses::ResponsePrompt?,
          speed: Float,
          temperature: Float,
          tool_choice: String,
          tools: ::Array[OpenAI::Realtime::RealtimeFunctionTool],
          tracing: OpenAI::Models::Realtime::RealtimeSession::tracing?,
          turn_detection: OpenAI::Models::Realtime::RealtimeSession::turn_detection?,
          voice: OpenAI::Models::Realtime::RealtimeSession::voice
        }

      class RealtimeSession < OpenAI::Internal::Type::BaseModel
        attr_reader id: String?

        def id=: (String) -> String

        attr_reader expires_at: Integer?

        def expires_at=: (Integer) -> Integer

        attr_accessor include: ::Array[OpenAI::Models::Realtime::RealtimeSession::include_]?

        attr_reader input_audio_format: OpenAI::Models::Realtime::RealtimeSession::input_audio_format?

        def input_audio_format=: (
          OpenAI::Models::Realtime::RealtimeSession::input_audio_format
        ) -> OpenAI::Models::Realtime::RealtimeSession::input_audio_format

        attr_reader input_audio_noise_reduction: OpenAI::Realtime::RealtimeSession::InputAudioNoiseReduction?

        def input_audio_noise_reduction=: (
          OpenAI::Realtime::RealtimeSession::InputAudioNoiseReduction
        ) -> OpenAI::Realtime::RealtimeSession::InputAudioNoiseReduction

        attr_accessor input_audio_transcription: OpenAI::Realtime::AudioTranscription?

        attr_reader instructions: String?

        def instructions=: (String) -> String

        attr_reader max_response_output_tokens: OpenAI::Models::Realtime::RealtimeSession::max_response_output_tokens?

        def max_response_output_tokens=: (
          OpenAI::Models::Realtime::RealtimeSession::max_response_output_tokens
        ) -> OpenAI::Models::Realtime::RealtimeSession::max_response_output_tokens

        attr_reader modalities: ::Array[OpenAI::Models::Realtime::RealtimeSession::modality]?

        def modalities=: (
          ::Array[OpenAI::Models::Realtime::RealtimeSession::modality]
        ) -> ::Array[OpenAI::Models::Realtime::RealtimeSession::modality]

        attr_reader model: OpenAI::Models::Realtime::RealtimeSession::model?

        def model=: (
          OpenAI::Models::Realtime::RealtimeSession::model
        ) -> OpenAI::Models::Realtime::RealtimeSession::model

        attr_reader object: OpenAI::Models::Realtime::RealtimeSession::object?

        def object=: (
          OpenAI::Models::Realtime::RealtimeSession::object
        ) -> OpenAI::Models::Realtime::RealtimeSession::object

        attr_reader output_audio_format: OpenAI::Models::Realtime::RealtimeSession::output_audio_format?

        def output_audio_format=: (
          OpenAI::Models::Realtime::RealtimeSession::output_audio_format
        ) -> OpenAI::Models::Realtime::RealtimeSession::output_audio_format

        attr_accessor prompt: OpenAI::Responses::ResponsePrompt?

        attr_reader speed: Float?

        def speed=: (Float) -> Float

        attr_reader temperature: Float?

        def temperature=: (Float) -> Float

        attr_reader tool_choice: String?

        def tool_choice=: (String) -> String

        attr_reader tools: ::Array[OpenAI::Realtime::RealtimeFunctionTool]?

        def tools=: (
          ::Array[OpenAI::Realtime::RealtimeFunctionTool]
        ) -> ::Array[OpenAI::Realtime::RealtimeFunctionTool]

        attr_accessor tracing: OpenAI::Models::Realtime::RealtimeSession::tracing?

        attr_accessor turn_detection: OpenAI::Models::Realtime::RealtimeSession::turn_detection?

        attr_reader voice: OpenAI::Models::Realtime::RealtimeSession::voice?

        def voice=: (
          OpenAI::Models::Realtime::RealtimeSession::voice
        ) -> OpenAI::Models::Realtime::RealtimeSession::voice

        def initialize: (
          ?id: String,
          ?expires_at: Integer,
          ?include: ::Array[OpenAI::Models::Realtime::RealtimeSession::include_]?,
          ?input_audio_format: OpenAI::Models::Realtime::RealtimeSession::input_audio_format,
          ?input_audio_noise_reduction: OpenAI::Realtime::RealtimeSession::InputAudioNoiseReduction,
          ?input_audio_transcription: OpenAI::Realtime::AudioTranscription?,
          ?instructions: String,
          ?max_response_output_tokens: OpenAI::Models::Realtime::RealtimeSession::max_response_output_tokens,
          ?modalities: ::Array[OpenAI::Models::Realtime::RealtimeSession::modality],
          ?model: OpenAI::Models::Realtime::RealtimeSession::model,
          ?object: OpenAI::Models::Realtime::RealtimeSession::object,
          ?output_audio_format: OpenAI::Models::Realtime::RealtimeSession::output_audio_format,
          ?prompt: OpenAI::Responses::ResponsePrompt?,
          ?speed: Float,
          ?temperature: Float,
          ?tool_choice: String,
          ?tools: ::Array[OpenAI::Realtime::RealtimeFunctionTool],
          ?tracing: OpenAI::Models::Realtime::RealtimeSession::tracing?,
          ?turn_detection: OpenAI::Models::Realtime::RealtimeSession::turn_detection?,
          ?voice: OpenAI::Models::Realtime::RealtimeSession::voice
        ) -> void

        def to_hash: -> {
          id: String,
          expires_at: Integer,
          include: ::Array[OpenAI::Models::Realtime::RealtimeSession::include_]?,
          input_audio_format: OpenAI::Models::Realtime::RealtimeSession::input_audio_format,
          input_audio_noise_reduction: OpenAI::Realtime::RealtimeSession::InputAudioNoiseReduction,
          input_audio_transcription: OpenAI::Realtime::AudioTranscription?,
          instructions: String,
          max_response_output_tokens: OpenAI::Models::Realtime::RealtimeSession::max_response_output_tokens,
          modalities: ::Array[OpenAI::Models::Realtime::RealtimeSession::modality],
          model: OpenAI::Models::Realtime::RealtimeSession::model,
          object: OpenAI::Models::Realtime::RealtimeSession::object,
          output_audio_format: OpenAI::Models::Realtime::RealtimeSession::output_audio_format,
          prompt: OpenAI::Responses::ResponsePrompt?,
          speed: Float,
          temperature: Float,
          tool_choice: String,
          tools: ::Array[OpenAI::Realtime::RealtimeFunctionTool],
          tracing: OpenAI::Models::Realtime::RealtimeSession::tracing?,
          turn_detection: OpenAI::Models::Realtime::RealtimeSession::turn_detection?,
          voice: OpenAI::Models::Realtime::RealtimeSession::voice
        }

        type include_ = :"item.input_audio_transcription.logprobs"

        module Include
          extend OpenAI::Internal::Type::Enum

          ITEM_INPUT_AUDIO_TRANSCRIPTION_LOGPROBS: :"item.input_audio_transcription.logprobs"

          def self?.values: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::include_]
        end

        type input_audio_format = :pcm16 | :g711_ulaw | :g711_alaw

        module InputAudioFormat
          extend OpenAI::Internal::Type::Enum

          PCM16: :pcm16
          G711_ULAW: :g711_ulaw
          G711_ALAW: :g711_alaw

          def self?.values: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::input_audio_format]
        end

        type input_audio_noise_reduction =
          { type: OpenAI::Models::Realtime::noise_reduction_type }

        class InputAudioNoiseReduction < OpenAI::Internal::Type::BaseModel
          attr_reader type: OpenAI::Models::Realtime::noise_reduction_type?

          def type=: (
            OpenAI::Models::Realtime::noise_reduction_type
          ) -> OpenAI::Models::Realtime::noise_reduction_type

          def initialize: (
            ?type: OpenAI::Models::Realtime::noise_reduction_type
          ) -> void

          def to_hash: -> {
            type: OpenAI::Models::Realtime::noise_reduction_type
          }
        end

        type max_response_output_tokens = Integer | :inf

        module MaxResponseOutputTokens
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::max_response_output_tokens]
        end

        type modality = :text | :audio

        module Modality
          extend OpenAI::Internal::Type::Enum

          TEXT: :text
          AUDIO: :audio

          def self?.values: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::modality]
        end

        type model =
          String
          | :"gpt-realtime"
          | :"gpt-realtime-2025-08-28"
          | :"gpt-4o-realtime-preview"
          | :"gpt-4o-realtime-preview-2024-10-01"
          | :"gpt-4o-realtime-preview-2024-12-17"
          | :"gpt-4o-realtime-preview-2025-06-03"
          | :"gpt-4o-mini-realtime-preview"
          | :"gpt-4o-mini-realtime-preview-2024-12-17"
          | :"gpt-realtime-mini"
          | :"gpt-realtime-mini-2025-10-06"
          | :"gpt-realtime-mini-2025-12-15"
          | :"gpt-audio-mini"
          | :"gpt-audio-mini-2025-10-06"
          | :"gpt-audio-mini-2025-12-15"

        module Model
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::model]

          GPT_REALTIME: :"gpt-realtime"
          GPT_REALTIME_2025_08_28: :"gpt-realtime-2025-08-28"
          GPT_4O_REALTIME_PREVIEW: :"gpt-4o-realtime-preview"
          GPT_4O_REALTIME_PREVIEW_2024_10_01: :"gpt-4o-realtime-preview-2024-10-01"
          GPT_4O_REALTIME_PREVIEW_2024_12_17: :"gpt-4o-realtime-preview-2024-12-17"
          GPT_4O_REALTIME_PREVIEW_2025_06_03: :"gpt-4o-realtime-preview-2025-06-03"
          GPT_4O_MINI_REALTIME_PREVIEW: :"gpt-4o-mini-realtime-preview"
          GPT_4O_MINI_REALTIME_PREVIEW_2024_12_17: :"gpt-4o-mini-realtime-preview-2024-12-17"
          GPT_REALTIME_MINI: :"gpt-realtime-mini"
          GPT_REALTIME_MINI_2025_10_06: :"gpt-realtime-mini-2025-10-06"
          GPT_REALTIME_MINI_2025_12_15: :"gpt-realtime-mini-2025-12-15"
          GPT_AUDIO_MINI: :"gpt-audio-mini"
          GPT_AUDIO_MINI_2025_10_06: :"gpt-audio-mini-2025-10-06"
          GPT_AUDIO_MINI_2025_12_15: :"gpt-audio-mini-2025-12-15"
        end

        type object = :"realtime.session"

        module Object
          extend OpenAI::Internal::Type::Enum

          REALTIME_SESSION: :"realtime.session"

          def self?.values: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::object]
        end

        type output_audio_format = :pcm16 | :g711_ulaw | :g711_alaw

        module OutputAudioFormat
          extend OpenAI::Internal::Type::Enum

          PCM16: :pcm16
          G711_ULAW: :g711_ulaw
          G711_ALAW: :g711_alaw

          def self?.values: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::output_audio_format]
        end

        type tracing =
          :auto
          | OpenAI::Realtime::RealtimeSession::Tracing::TracingConfiguration

        module Tracing
          extend OpenAI::Internal::Type::Union

          type tracing_configuration =
            { group_id: String, metadata: top, workflow_name: String }

          class TracingConfiguration < OpenAI::Internal::Type::BaseModel
            attr_reader group_id: String?

            def group_id=: (String) -> String

            attr_reader metadata: top?

            def metadata=: (top) -> top

            attr_reader workflow_name: String?

            def workflow_name=: (String) -> String

            def initialize: (
              ?group_id: String,
              ?metadata: top,
              ?workflow_name: String
            ) -> void

            def to_hash: -> {
              group_id: String,
              metadata: top,
              workflow_name: String
            }
          end

          def self?.variants: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::tracing]
        end

        type turn_detection =
          OpenAI::Realtime::RealtimeSession::TurnDetection::ServerVad
          | OpenAI::Realtime::RealtimeSession::TurnDetection::SemanticVad

        module TurnDetection
          extend OpenAI::Internal::Type::Union

          type server_vad =
            {
              type: :server_vad,
              create_response: bool,
              idle_timeout_ms: Integer?,
              interrupt_response: bool,
              prefix_padding_ms: Integer,
              silence_duration_ms: Integer,
              threshold: Float
            }

          class ServerVad < OpenAI::Internal::Type::BaseModel
            attr_accessor type: :server_vad

            attr_reader create_response: bool?

            def create_response=: (bool) -> bool

            attr_accessor idle_timeout_ms: Integer?

            attr_reader interrupt_response: bool?

            def interrupt_response=: (bool) -> bool

            attr_reader prefix_padding_ms: Integer?

            def prefix_padding_ms=: (Integer) -> Integer

            attr_reader silence_duration_ms: Integer?

            def silence_duration_ms=: (Integer) -> Integer

            attr_reader threshold: Float?

            def threshold=: (Float) -> Float

            def initialize: (
              ?create_response: bool,
              ?idle_timeout_ms: Integer?,
              ?interrupt_response: bool,
              ?prefix_padding_ms: Integer,
              ?silence_duration_ms: Integer,
              ?threshold: Float,
              ?type: :server_vad
            ) -> void

            def to_hash: -> {
              type: :server_vad,
              create_response: bool,
              idle_timeout_ms: Integer?,
              interrupt_response: bool,
              prefix_padding_ms: Integer,
              silence_duration_ms: Integer,
              threshold: Float
            }
          end

          type semantic_vad =
            {
              type: :semantic_vad,
              create_response: bool,
              eagerness: OpenAI::Models::Realtime::RealtimeSession::TurnDetection::SemanticVad::eagerness,
              interrupt_response: bool
            }

          class SemanticVad < OpenAI::Internal::Type::BaseModel
            attr_accessor type: :semantic_vad

            attr_reader create_response: bool?

            def create_response=: (bool) -> bool

            attr_reader eagerness: OpenAI::Models::Realtime::RealtimeSession::TurnDetection::SemanticVad::eagerness?

            def eagerness=: (
              OpenAI::Models::Realtime::RealtimeSession::TurnDetection::SemanticVad::eagerness
            ) -> OpenAI::Models::Realtime::RealtimeSession::TurnDetection::SemanticVad::eagerness

            attr_reader interrupt_response: bool?

            def interrupt_response=: (bool) -> bool

            def initialize: (
              ?create_response: bool,
              ?eagerness: OpenAI::Models::Realtime::RealtimeSession::TurnDetection::SemanticVad::eagerness,
              ?interrupt_response: bool,
              ?type: :semantic_vad
            ) -> void

            def to_hash: -> {
              type: :semantic_vad,
              create_response: bool,
              eagerness: OpenAI::Models::Realtime::RealtimeSession::TurnDetection::SemanticVad::eagerness,
              interrupt_response: bool
            }

            type eagerness = :low | :medium | :high | :auto

            module Eagerness
              extend OpenAI::Internal::Type::Enum

              LOW: :low
              MEDIUM: :medium
              HIGH: :high
              AUTO: :auto

              def self?.values: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::TurnDetection::SemanticVad::eagerness]
            end
          end

          def self?.variants: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::turn_detection]
        end

        type voice =
          String
          | :alloy
          | :ash
          | :ballad
          | :coral
          | :echo
          | :sage
          | :shimmer
          | :verse
          | :marin
          | :cedar

        module Voice
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Realtime::RealtimeSession::voice]

          ALLOY: :alloy
          ASH: :ash
          BALLAD: :ballad
          CORAL: :coral
          ECHO: :echo
          SAGE: :sage
          SHIMMER: :shimmer
          VERSE: :verse
          MARIN: :marin
          CEDAR: :cedar
        end
      end
    end
  end
end
