module OpenAI
  module Resources
    class Responses
      attr_reader input_items: OpenAI::Resources::Responses::InputItems

      def create: (
        input: OpenAI::Models::Responses::ResponseCreateParams::input,
        model: OpenAI::Models::Responses::ResponseCreateParams::model,
        ?include: ::Array[OpenAI::Models::Responses::response_includable]?,
        ?instructions: String?,
        ?max_output_tokens: Integer?,
        ?metadata: OpenAI::Models::metadata?,
        ?parallel_tool_calls: bool?,
        ?previous_response_id: String?,
        ?reasoning: OpenAI::Models::Reasoning?,
        ?store: bool?,
        ?temperature: Float?,
        ?text: OpenAI::Models::Responses::ResponseTextConfig,
        ?tool_choice: OpenAI::Models::Responses::ResponseCreateParams::tool_choice,
        ?tools: ::Array[OpenAI::Models::Responses::tool],
        ?top_p: Float?,
        ?truncation: OpenAI::Models::Responses::ResponseCreateParams::truncation?,
        ?user: String,
        ?request_options: OpenAI::request_opts
      ) -> OpenAI::Models::Responses::Response

      def create_streaming: (
        input: OpenAI::Models::Responses::ResponseCreateParams::input,
        model: OpenAI::Models::Responses::ResponseCreateParams::model,
        ?include: ::Array[OpenAI::Models::Responses::response_includable]?,
        ?instructions: String?,
        ?max_output_tokens: Integer?,
        ?metadata: OpenAI::Models::metadata?,
        ?parallel_tool_calls: bool?,
        ?previous_response_id: String?,
        ?reasoning: OpenAI::Models::Reasoning?,
        ?store: bool?,
        ?temperature: Float?,
        ?text: OpenAI::Models::Responses::ResponseTextConfig,
        ?tool_choice: OpenAI::Models::Responses::ResponseCreateParams::tool_choice,
        ?tools: ::Array[OpenAI::Models::Responses::tool],
        ?top_p: Float?,
        ?truncation: OpenAI::Models::Responses::ResponseCreateParams::truncation?,
        ?user: String,
        ?request_options: OpenAI::request_opts
      ) -> OpenAI::Stream[OpenAI::Models::Responses::response_stream_event]

      def retrieve: (
        String response_id,
        ?include: ::Array[OpenAI::Models::Responses::response_includable],
        ?request_options: OpenAI::request_opts
      ) -> OpenAI::Models::Responses::Response

      def delete: (
        String response_id,
        ?request_options: OpenAI::request_opts
      ) -> nil

      def initialize: (client: OpenAI::Client) -> void
    end
  end
end
