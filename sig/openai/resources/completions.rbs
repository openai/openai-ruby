module OpenAI
  module Resources
    class Completions
      def create: (
        model: OpenAI::Models::CompletionCreateParams::model,
        prompt: OpenAI::Models::CompletionCreateParams::prompt?,
        ?best_of: Integer?,
        ?echo: bool?,
        ?frequency_penalty: Float?,
        ?logit_bias: ::Hash[Symbol, Integer]?,
        ?logprobs: Integer?,
        ?max_tokens: Integer?,
        ?n: Integer?,
        ?presence_penalty: Float?,
        ?seed: Integer?,
        ?stop: OpenAI::Models::CompletionCreateParams::stop?,
        ?stream_options: OpenAI::Models::Chat::ChatCompletionStreamOptions?,
        ?suffix: String?,
        ?temperature: Float?,
        ?top_p: Float?,
        ?user: String,
        ?request_options: OpenAI::request_opts
      ) -> OpenAI::Models::Completion

      def create_streaming: (
        model: OpenAI::Models::CompletionCreateParams::model,
        prompt: OpenAI::Models::CompletionCreateParams::prompt?,
        ?best_of: Integer?,
        ?echo: bool?,
        ?frequency_penalty: Float?,
        ?logit_bias: ::Hash[Symbol, Integer]?,
        ?logprobs: Integer?,
        ?max_tokens: Integer?,
        ?n: Integer?,
        ?presence_penalty: Float?,
        ?seed: Integer?,
        ?stop: OpenAI::Models::CompletionCreateParams::stop?,
        ?stream_options: OpenAI::Models::Chat::ChatCompletionStreamOptions?,
        ?suffix: String?,
        ?temperature: Float?,
        ?top_p: Float?,
        ?user: String,
        ?request_options: OpenAI::request_opts
      ) -> OpenAI::Internal::Stream[OpenAI::Models::Completion]

      def initialize: (client: OpenAI::Client) -> void
    end
  end
end
